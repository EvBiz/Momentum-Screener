{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86772b6a",
   "metadata": {},
   "source": [
    "# Momentum Screener\n",
    "\n",
    "\n",
    "The gist of this methodology is essentially to:\n",
    "\n",
    "    1.) Penalize for Volatility\n",
    "    2.) Buy non-news driven momentum - FIP helps filter for this\n",
    "\n",
    "\n",
    "Process:\n",
    "\n",
    "1.) Omit top % decile of the most volatile stocks in our universe\n",
    "\n",
    "2.) 1yr/6month Volatiltiy Adjusted Returns: Calculate 1yr and 6month volatiltiy-adjusted returns and sort them highest to lowest - based on a combined 1yr & 6month score\n",
    "\n",
    "3.) FIP (Momentum Quality): Calculate FIP for the top 50% of the stocks from the vol-adjsuted reteurn screen\n",
    "\n",
    "4.) Rank Tickers: Calculate combined score based on the 1yr/6month vol-adjusted score and also the FIP score\n",
    "\n",
    "5.) Purchase the top 40-50 equities from the universe (or a % based)\n",
    "\n",
    "6.) Volatility Targetting: Volatility Targetted position sizing based on desired portfolio vol\n",
    "\n",
    "7.) Rebalance: Rebalance monthly OR rebalance based on EV > Cost of rebalancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "e84fe66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import yfinance as yf\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "19ea4528",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NVDA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MSFT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AMZN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>META</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ticker\n",
       "0   NVDA\n",
       "1   MSFT\n",
       "2   AAPL\n",
       "3   AMZN\n",
       "4   META"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp500_tickers = pd.read_csv('sp500_tickers.csv')  # Assuming you have a file of S&P500 tickers\n",
    "sp500_tickers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9d81c8-b552-49f7-810c-8e705f6a8bb7",
   "metadata": {},
   "source": [
    "# Omit Top Decile of Highest 1Y Volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "721719b5-60d8-4936-9b1d-57bb512e1353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a blank dataframe with the appropriate columns\n",
    "df = pd.DataFrame(columns=['Ticker', 'Historical Volatility'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "de02298a-c806-4c82-8fc7-a2d118285d9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  893 of 893 completed\n",
      "\n",
      "31 Failed downloads:\n",
      "['NCR', 'JWN', 'PDCO', 'SWAV', 'AZPN', 'PACW', 'SYNH', 'OFC', 'LHCG', 'STOR', 'ETRN', 'SRC', 'UNVR', 'BRK.B', 'GPS', 'NARI', 'PNM', 'IAA', 'LSI', 'WWE', 'AIRC', 'UMPQ', 'RCM', 'ENV', 'SWN', 'TPX', 'NATI', 'NYCB', 'PDCE']: YFPricesMissingError('possibly delisted; no price data found  (period=2y) (Yahoo error = \"No data found, symbol may be delisted\")')\n",
      "['PVH']: Timeout('Failed to perform, curl: (28) Operation timed out after 10003 milliseconds with 10 bytes received. See https://curl.se/libcurl/c/libcurl-errors.html first for more details.')\n",
      "['BF.B']: YFPricesMissingError('possibly delisted; no price data found  (period=2y)')\n",
      "C:\\Users\\eabiz\\AppData\\Local\\Temp\\ipykernel_11904\\1680125838.py:20: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  ticker_data['Daily Return'] = ticker_data['Close'].pct_change()\n",
      "C:\\Users\\eabiz\\AppData\\Local\\Temp\\ipykernel_11904\\1680125838.py:20: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  ticker_data['Daily Return'] = ticker_data['Close'].pct_change()\n",
      "C:\\Users\\eabiz\\AppData\\Local\\Temp\\ipykernel_11904\\1680125838.py:20: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  ticker_data['Daily Return'] = ticker_data['Close'].pct_change()\n",
      "C:\\Users\\eabiz\\AppData\\Local\\Temp\\ipykernel_11904\\1680125838.py:20: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  ticker_data['Daily Return'] = ticker_data['Close'].pct_change()\n",
      "C:\\Users\\eabiz\\AppData\\Local\\Temp\\ipykernel_11904\\1680125838.py:20: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  ticker_data['Daily Return'] = ticker_data['Close'].pct_change()\n",
      "C:\\Users\\eabiz\\AppData\\Local\\Temp\\ipykernel_11904\\1680125838.py:20: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  ticker_data['Daily Return'] = ticker_data['Close'].pct_change()\n",
      "C:\\Users\\eabiz\\AppData\\Local\\Temp\\ipykernel_11904\\1680125838.py:20: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  ticker_data['Daily Return'] = ticker_data['Close'].pct_change()\n",
      "C:\\Users\\eabiz\\AppData\\Local\\Temp\\ipykernel_11904\\1680125838.py:20: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  ticker_data['Daily Return'] = ticker_data['Close'].pct_change()\n",
      "C:\\Users\\eabiz\\AppData\\Local\\Temp\\ipykernel_11904\\1680125838.py:20: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  ticker_data['Daily Return'] = ticker_data['Close'].pct_change()\n",
      "C:\\Users\\eabiz\\AppData\\Local\\Temp\\ipykernel_11904\\1680125838.py:20: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  ticker_data['Daily Return'] = ticker_data['Close'].pct_change()\n",
      "C:\\Users\\eabiz\\AppData\\Local\\Temp\\ipykernel_11904\\1680125838.py:20: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  ticker_data['Daily Return'] = ticker_data['Close'].pct_change()\n",
      "C:\\Users\\eabiz\\AppData\\Local\\Temp\\ipykernel_11904\\1680125838.py:20: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  ticker_data['Daily Return'] = ticker_data['Close'].pct_change()\n",
      "C:\\Users\\eabiz\\AppData\\Local\\Temp\\ipykernel_11904\\1680125838.py:20: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  ticker_data['Daily Return'] = ticker_data['Close'].pct_change()\n",
      "C:\\Users\\eabiz\\AppData\\Local\\Temp\\ipykernel_11904\\1680125838.py:20: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  ticker_data['Daily Return'] = ticker_data['Close'].pct_change()\n",
      "C:\\Users\\eabiz\\AppData\\Local\\Temp\\ipykernel_11904\\1680125838.py:20: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  ticker_data['Daily Return'] = ticker_data['Close'].pct_change()\n",
      "C:\\Users\\eabiz\\AppData\\Local\\Temp\\ipykernel_11904\\1680125838.py:20: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  ticker_data['Daily Return'] = ticker_data['Close'].pct_change()\n",
      "C:\\Users\\eabiz\\AppData\\Local\\Temp\\ipykernel_11904\\1680125838.py:20: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  ticker_data['Daily Return'] = ticker_data['Close'].pct_change()\n",
      "C:\\Users\\eabiz\\AppData\\Local\\Temp\\ipykernel_11904\\1680125838.py:20: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  ticker_data['Daily Return'] = ticker_data['Close'].pct_change()\n",
      "C:\\Users\\eabiz\\AppData\\Local\\Temp\\ipykernel_11904\\1680125838.py:20: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  ticker_data['Daily Return'] = ticker_data['Close'].pct_change()\n",
      "C:\\Users\\eabiz\\AppData\\Local\\Temp\\ipykernel_11904\\1680125838.py:20: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  ticker_data['Daily Return'] = ticker_data['Close'].pct_change()\n",
      "C:\\Users\\eabiz\\AppData\\Local\\Temp\\ipykernel_11904\\1680125838.py:20: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  ticker_data['Daily Return'] = ticker_data['Close'].pct_change()\n",
      "C:\\Users\\eabiz\\AppData\\Local\\Temp\\ipykernel_11904\\1680125838.py:20: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  ticker_data['Daily Return'] = ticker_data['Close'].pct_change()\n",
      "C:\\Users\\eabiz\\AppData\\Local\\Temp\\ipykernel_11904\\1680125838.py:20: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  ticker_data['Daily Return'] = ticker_data['Close'].pct_change()\n",
      "C:\\Users\\eabiz\\AppData\\Local\\Temp\\ipykernel_11904\\1680125838.py:20: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  ticker_data['Daily Return'] = ticker_data['Close'].pct_change()\n",
      "C:\\Users\\eabiz\\AppData\\Local\\Temp\\ipykernel_11904\\1680125838.py:20: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  ticker_data['Daily Return'] = ticker_data['Close'].pct_change()\n",
      "C:\\Users\\eabiz\\AppData\\Local\\Temp\\ipykernel_11904\\1680125838.py:20: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  ticker_data['Daily Return'] = ticker_data['Close'].pct_change()\n",
      "C:\\Users\\eabiz\\AppData\\Local\\Temp\\ipykernel_11904\\1680125838.py:20: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  ticker_data['Daily Return'] = ticker_data['Close'].pct_change()\n",
      "C:\\Users\\eabiz\\AppData\\Local\\Temp\\ipykernel_11904\\1680125838.py:20: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  ticker_data['Daily Return'] = ticker_data['Close'].pct_change()\n",
      "C:\\Users\\eabiz\\AppData\\Local\\Temp\\ipykernel_11904\\1680125838.py:20: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  ticker_data['Daily Return'] = ticker_data['Close'].pct_change()\n",
      "C:\\Users\\eabiz\\AppData\\Local\\Temp\\ipykernel_11904\\1680125838.py:20: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  ticker_data['Daily Return'] = ticker_data['Close'].pct_change()\n",
      "C:\\Users\\eabiz\\AppData\\Local\\Temp\\ipykernel_11904\\1680125838.py:20: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  ticker_data['Daily Return'] = ticker_data['Close'].pct_change()\n",
      "C:\\Users\\eabiz\\AppData\\Local\\Temp\\ipykernel_11904\\1680125838.py:20: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  ticker_data['Daily Return'] = ticker_data['Close'].pct_change()\n",
      "C:\\Users\\eabiz\\AppData\\Local\\Temp\\ipykernel_11904\\1680125838.py:20: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  ticker_data['Daily Return'] = ticker_data['Close'].pct_change()\n",
      "C:\\Users\\eabiz\\AppData\\Local\\Temp\\ipykernel_11904\\1680125838.py:20: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  ticker_data['Daily Return'] = ticker_data['Close'].pct_change()\n",
      "C:\\Users\\eabiz\\AppData\\Local\\Temp\\ipykernel_11904\\1680125838.py:20: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  ticker_data['Daily Return'] = ticker_data['Close'].pct_change()\n",
      "C:\\Users\\eabiz\\AppData\\Local\\Temp\\ipykernel_11904\\1680125838.py:20: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  ticker_data['Daily Return'] = ticker_data['Close'].pct_change()\n"
     ]
    }
   ],
   "source": [
    "# Collect rows in a list for concatenation\n",
    "rows_to_add = []\n",
    "\n",
    "# Convert tickers column to a list\n",
    "tickers = sp500_tickers['ticker'].tolist()\n",
    "\n",
    "# Batch download all tickers at once\n",
    "data = yf.download(tickers, period='2y', group_by='ticker', threads=True, auto_adjust=False)\n",
    "\n",
    "for ticker in tickers:  # Iterate over the 'ticker' list\n",
    "    try:\n",
    "        # Retrieve individual ticker data from multi-ticker DataFrame\n",
    "        ticker_data = data[ticker].copy()\n",
    "\n",
    "        # Check if data is insufficient\n",
    "        if ticker_data.empty or len(ticker_data) < 252:  \n",
    "            raise ValueError(f\"Insufficient data for ticker: {ticker}\") \n",
    "\n",
    "        # Calculate daily returns\n",
    "        ticker_data['Daily Return'] = ticker_data['Close'].pct_change()\n",
    "\n",
    "        # Rolling window for std\n",
    "        window = 252  \n",
    "\n",
    "        # Calculate rolling std of daily returns\n",
    "        ticker_data['Rolling_Std'] = ticker_data['Daily Return'].rolling(window).std()\n",
    "\n",
    "        # Annualize rolling standard deviation to get historical annual volatility\n",
    "        ticker_data['Rolling_Hist_Vol'] = ticker_data['Rolling_Std'] * np.sqrt(window)\n",
    "\n",
    "        # Retrieve the last value of Vol Adjusted Return\n",
    "        historical_vol = ticker_data['Rolling_Hist_Vol'].iat[-1]\n",
    "\n",
    "        # Add the result to the list\n",
    "        rows_to_add.append({'Ticker': ticker, 'Historical Volatility': historical_vol})\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving data for {ticker}: {str(e)}\")\n",
    "\n",
    "# Concatenate all rows into the DataFrame at once\n",
    "df = pd.concat([pd.DataFrame(rows_to_add)], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "35278b70-acd9-4d87-8346-e7506e2de92c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Historical Volatility</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>WOLF</td>\n",
       "      <td>2.287804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>SMCI</td>\n",
       "      <td>1.148221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>RUN</td>\n",
       "      <td>1.105152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>VSAT</td>\n",
       "      <td>1.052422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>790</th>\n",
       "      <td>FL</td>\n",
       "      <td>1.003620</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Ticker  Historical Volatility\n",
       "541   WOLF               2.287804\n",
       "265   SMCI               1.148221\n",
       "720    RUN               1.105152\n",
       "886   VSAT               1.052422\n",
       "790     FL               1.003620"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sort_values('Historical Volatility', ascending=False) #highest Vol at the top\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2583f27f-875f-4ffe-8236-6213c4cc3d08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Historical Volatility</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>CNC</td>\n",
       "      <td>0.539264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>ALGN</td>\n",
       "      <td>0.538459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>TER</td>\n",
       "      <td>0.536193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>OMCL</td>\n",
       "      <td>0.535949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>X</td>\n",
       "      <td>0.534247</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Ticker  Historical Volatility\n",
       "440    CNC               0.539264\n",
       "472   ALGN               0.538459\n",
       "397    TER               0.536193\n",
       "890   OMCL               0.535949\n",
       "628      X               0.534247"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sort_values('Historical Volatility', ascending=False) #highest Vol at the top\n",
    "\n",
    "# Determine the 90th percentile threshold (top 10% cutoff)\n",
    "vol_threshold = df['Historical Volatility'].quantile(0.90)\n",
    "\n",
    "# Drop tickers in the top decile\n",
    "df = df[df['Historical Volatility'] <= vol_threshold]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "0a637071-00cf-4f65-9800-ceb263f1bb78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>CNC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>ALGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>TER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>OMCL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ticker\n",
       "440    CNC\n",
       "472   ALGN\n",
       "397    TER\n",
       "890   OMCL\n",
       "628      X"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp500_tickers = df # rename dataframe to sp500 tickers for the loops\n",
    "\n",
    "sp500_tickers.drop(columns=['Historical Volatility'],inplace=True)\n",
    "sp500_tickers.rename(columns={'Ticker' : 'ticker'},inplace=True)\n",
    "sp500_tickers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe60873",
   "metadata": {},
   "source": [
    "# Volatility Adjusted Returns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ce0240-d6f4-4a39-9aa8-b8e77a3dd45c",
   "metadata": {},
   "source": [
    "#### 1.) 1Y Volatility-Adjusted Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "85bdcf95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a blank dataframe with the appropriate columns\n",
    "df = pd.DataFrame(columns=['Ticker', 'Vol Adjusted Return'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "ccb67ed5-2e98-4d20-8b2d-4984a5ba1364",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  775 of 775 completed\n",
      "C:\\Users\\eabiz\\AppData\\Local\\Temp\\ipykernel_11904\\2641018204.py:20: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  ticker_data['Daily Return'] = ticker_data['Close'].pct_change()\n",
      "C:\\Users\\eabiz\\AppData\\Local\\Temp\\ipykernel_11904\\2641018204.py:20: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  ticker_data['Daily Return'] = ticker_data['Close'].pct_change()\n",
      "C:\\Users\\eabiz\\AppData\\Local\\Temp\\ipykernel_11904\\2641018204.py:20: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  ticker_data['Daily Return'] = ticker_data['Close'].pct_change()\n",
      "C:\\Users\\eabiz\\AppData\\Local\\Temp\\ipykernel_11904\\2641018204.py:20: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  ticker_data['Daily Return'] = ticker_data['Close'].pct_change()\n"
     ]
    }
   ],
   "source": [
    "# Collect rows in a list for concatenation\n",
    "rows_to_add = []\n",
    "\n",
    "# Convert tickers column to a list\n",
    "tickers = sp500_tickers['ticker'].tolist()\n",
    "\n",
    "# Batch download 2 years of data for all tickers at once\n",
    "data = yf.download(tickers, period='2y', group_by='ticker', threads=True, auto_adjust=False)\n",
    "\n",
    "for ticker in tickers:  # Iterate over the 'ticker' column in sp500_tickers dataframe\n",
    "    try:\n",
    "        # Retrieve individual ticker data from multi-ticker DataFrame\n",
    "        ticker_data = data[ticker].copy()\n",
    "\n",
    "        # Check if data is insufficient\n",
    "        if ticker_data.empty or len(ticker_data) < 252:  \n",
    "            raise ValueError(f\"Insufficient data for ticker: {ticker}\")\n",
    "\n",
    "        # Calculate daily returns\n",
    "        ticker_data['Daily Return'] = ticker_data['Close'].pct_change()\n",
    "\n",
    "        # Calculate percent return over a 1-year period (252 trading days)\n",
    "        ticker_data['Percent Return'] = ((ticker_data['Close'] - ticker_data['Close'].shift(252)) / ticker_data['Close'].shift(252)) * 100  \n",
    "\n",
    "        # Rolling window for std dev (daily returns)\n",
    "        window = 252  \n",
    "\n",
    "        # Calculate rolling standard deviation of daily returns\n",
    "        ticker_data['Rolling_Std'] = ticker_data['Daily Return'].rolling(window).std()\n",
    "\n",
    "        # Annualize rolling standard deviation to get historical annual volatility\n",
    "        ticker_data['Rolling_Hist_Vol'] = ticker_data['Rolling_Std'] * np.sqrt(window)\n",
    "\n",
    "        # Calculate volatility-adjusted returns\n",
    "        ticker_data['Vol_Adjusted_Return'] = ((ticker_data['Percent Return'])/100) / (ticker_data['Rolling_Hist_Vol'])\n",
    "\n",
    "        # Retrieve the last value of Vol Adjusted Return\n",
    "        vol_adjusted_return = ticker_data['Vol_Adjusted_Return'].iat[-1]\n",
    "\n",
    "        # Add the result to the list\n",
    "        rows_to_add.append({'Ticker': ticker, 'Vol Adjusted Return': vol_adjusted_return})\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving data for {ticker}: {str(e)}\")\n",
    "\n",
    "# Concatenate all rows into the DataFrame at once\n",
    "df = pd.concat([pd.DataFrame(rows_to_add)], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b5bf77c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values('Vol Adjusted Return', ascending=False)\n",
    "# Create a csv file with the results\n",
    "df.to_csv(\"Momentum Screen Results.csv\", index=False) # set index = to false, or else it'll create a column with index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "0c92a3aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Vol Adjusted Return</th>\n",
       "      <th>Index1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TPR</td>\n",
       "      <td>4.498198</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JBL</td>\n",
       "      <td>3.253323</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DASH</td>\n",
       "      <td>3.245977</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IBKR</td>\n",
       "      <td>3.088371</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HWM</td>\n",
       "      <td>2.995266</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Ticker  Vol Adjusted Return  Index1\n",
       "0    TPR             4.498198       0\n",
       "1    JBL             3.253323       1\n",
       "2   DASH             3.245977       2\n",
       "3   IBKR             3.088371       3\n",
       "4    HWM             2.995266       4"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the csv file - momentum screen results\n",
    "df1 = pd.read_csv(\"Momentum Screen Results.csv\")\n",
    "\n",
    "df1['Index1'] = df1.index # create column of the index position\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba01814-9ee8-415e-a9a6-1cb0c8ffb178",
   "metadata": {},
   "source": [
    "### 2.) 6M Volatility Adjusted Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "84d8cc0f-ab42-4e8d-b912-9037cd58ec20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a blank dataframe with the appropriate columns\n",
    "df = pd.DataFrame(columns=['Ticker', 'Vol Adjusted Return'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "63f716d8-9aba-40c9-92de-27e8ddec1cac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  775 of 775 completed\n",
      "C:\\Users\\eabiz\\AppData\\Local\\Temp\\ipykernel_11904\\3556766263.py:20: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  ticker_data['Daily Return'] = ticker_data['Close'].pct_change()\n",
      "C:\\Users\\eabiz\\AppData\\Local\\Temp\\ipykernel_11904\\3556766263.py:20: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  ticker_data['Daily Return'] = ticker_data['Close'].pct_change()\n",
      "C:\\Users\\eabiz\\AppData\\Local\\Temp\\ipykernel_11904\\3556766263.py:20: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  ticker_data['Daily Return'] = ticker_data['Close'].pct_change()\n",
      "C:\\Users\\eabiz\\AppData\\Local\\Temp\\ipykernel_11904\\3556766263.py:20: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  ticker_data['Daily Return'] = ticker_data['Close'].pct_change()\n"
     ]
    }
   ],
   "source": [
    "# Collect rows in a list for concatenation\n",
    "rows_to_add = []\n",
    "\n",
    "# Convert tickers column to a list\n",
    "tickers = sp500_tickers['ticker'].tolist()\n",
    "\n",
    "# Batch download 1 year of data for all tickers at once\n",
    "data = yf.download(tickers, period='1y', group_by='ticker', threads=True, auto_adjust=False)\n",
    "\n",
    "for ticker in tickers:  # Iterate over the 'ticker' column in sp500_tickers dataframe\n",
    "    try:\n",
    "        # Retrieve individual ticker data from multi-ticker DataFrame\n",
    "        ticker_data = data[ticker].copy()\n",
    "        \n",
    "        # Check if data is insufficient\n",
    "        if ticker_data.empty or len(ticker_data) < 126:  \n",
    "            raise ValueError(f\"Insufficient data for ticker: {ticker}\")\n",
    "\n",
    "        # Calculate daily returns\n",
    "        ticker_data['Daily Return'] = ticker_data['Close'].pct_change()\n",
    "\n",
    "        # Calculate percent return over a 1-year period (252 trading days)\n",
    "        ticker_data['Percent Return'] = ((ticker_data['Close'] - ticker_data['Close'].shift(126)) / ticker_data['Close'].shift(126)) * 100  \n",
    "\n",
    "        # Rolling window for std dev (daily returns)\n",
    "        window = 126  \n",
    "\n",
    "        # Calculate rolling standard deviation of daily returns\n",
    "        ticker_data['Rolling_Std'] = ticker_data['Daily Return'].rolling(window).std()\n",
    "\n",
    "        # Annualize rolling standard deviation to get historical annual volatility\n",
    "        ticker_data['Rolling_Hist_Vol'] = ticker_data['Rolling_Std'] * np.sqrt(252)\n",
    "\n",
    "        # Calculate volatility-adjusted returns\n",
    "        ticker_data['Vol_Adjusted_Return'] = ((ticker_data['Percent Return'])/100) / (ticker_data['Rolling_Hist_Vol'])\n",
    "\n",
    "        # Retrieve the last value of Vol Adjusted Return\n",
    "        vol_adjusted_return = ticker_data['Vol_Adjusted_Return'].iat[-1]\n",
    "\n",
    "        # Add the result to the list\n",
    "        rows_to_add.append({'Ticker': ticker, 'Vol Adjusted Return': vol_adjusted_return})\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving data for {ticker}: {str(e)}\")\n",
    "\n",
    "# Concatenate all rows into the DataFrame at once\n",
    "df = pd.concat([pd.DataFrame(rows_to_add)], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "43123288-e83c-47c5-bdb3-ed0fee32d129",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values('Vol Adjusted Return', ascending=False)\n",
    "# Create a csv file with the results\n",
    "df.to_csv(\"6 Month Momentum Screen Results.csv\", index=False) # set index = to false, or else it'll create a column with index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "d06a2740-c9da-46b5-8a7f-f852b1e4820b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Vol Adjusted Return</th>\n",
       "      <th>Index2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NEU</td>\n",
       "      <td>1.719420</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SXT</td>\n",
       "      <td>1.578279</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>APH</td>\n",
       "      <td>1.518146</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LHX</td>\n",
       "      <td>1.410538</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ORA</td>\n",
       "      <td>1.407010</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Ticker  Vol Adjusted Return  Index2\n",
       "0    NEU             1.719420       0\n",
       "1    SXT             1.578279       1\n",
       "2    APH             1.518146       2\n",
       "3    LHX             1.410538       3\n",
       "4    ORA             1.407010       4"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv(\"6 Month Momentum Screen Results.csv\")\n",
    "df2['Index2'] = df2.index # create column of the index position\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46124942-4a4b-4c6a-90f3-80af3c534a0f",
   "metadata": {},
   "source": [
    "### Merge Both Dataframes - 1Y and 6M vol volatility adjusted returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "e1775301-68e1-41f8-ade1-884e7548eafd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Vol Adjusted Return_x</th>\n",
       "      <th>Index1</th>\n",
       "      <th>Vol Adjusted Return_y</th>\n",
       "      <th>Index2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TPR</td>\n",
       "      <td>4.498198</td>\n",
       "      <td>0</td>\n",
       "      <td>0.983924</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JBL</td>\n",
       "      <td>3.253323</td>\n",
       "      <td>1</td>\n",
       "      <td>0.791529</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DASH</td>\n",
       "      <td>3.245977</td>\n",
       "      <td>2</td>\n",
       "      <td>0.792263</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IBKR</td>\n",
       "      <td>3.088371</td>\n",
       "      <td>3</td>\n",
       "      <td>0.180794</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HWM</td>\n",
       "      <td>2.995266</td>\n",
       "      <td>4</td>\n",
       "      <td>0.999026</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Ticker  Vol Adjusted Return_x  Index1  Vol Adjusted Return_y  Index2\n",
       "0    TPR               4.498198       0               0.983924      19\n",
       "1    JBL               3.253323       1               0.791529      51\n",
       "2   DASH               3.245977       2               0.792263      50\n",
       "3   IBKR               3.088371       3               0.180794     238\n",
       "4    HWM               2.995266       4               0.999026      18"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform an inner join to include only matching tickers\n",
    "df = pd.merge(df1, df2, on='Ticker', how='inner')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f7fb03-a244-4d26-a0b5-539446e632a2",
   "metadata": {},
   "source": [
    "### Calculate Average Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "0e140a4d-2190-44c6-961f-cb0db8f56be3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Vol Adjusted Return_x</th>\n",
       "      <th>Index1</th>\n",
       "      <th>Vol Adjusted Return_y</th>\n",
       "      <th>Index2</th>\n",
       "      <th>average_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TPR</td>\n",
       "      <td>4.498198</td>\n",
       "      <td>0</td>\n",
       "      <td>0.983924</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JBL</td>\n",
       "      <td>3.253323</td>\n",
       "      <td>1</td>\n",
       "      <td>0.791529</td>\n",
       "      <td>51</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DASH</td>\n",
       "      <td>3.245977</td>\n",
       "      <td>2</td>\n",
       "      <td>0.792263</td>\n",
       "      <td>50</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IBKR</td>\n",
       "      <td>3.088371</td>\n",
       "      <td>3</td>\n",
       "      <td>0.180794</td>\n",
       "      <td>238</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HWM</td>\n",
       "      <td>2.995266</td>\n",
       "      <td>4</td>\n",
       "      <td>0.999026</td>\n",
       "      <td>18</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Ticker  Vol Adjusted Return_x  Index1  Vol Adjusted Return_y  Index2  \\\n",
       "0    TPR               4.498198       0               0.983924      19   \n",
       "1    JBL               3.253323       1               0.791529      51   \n",
       "2   DASH               3.245977       2               0.792263      50   \n",
       "3   IBKR               3.088371       3               0.180794     238   \n",
       "4    HWM               2.995266       4               0.999026      18   \n",
       "\n",
       "   average_rank  \n",
       "0            19  \n",
       "1            52  \n",
       "2            52  \n",
       "3           241  \n",
       "4            22  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate average rank\n",
    "\n",
    "df['average_rank'] = df['Index1'] + df['Index2'] # simply add the two ranks\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "4e90e1de-42e4-489c-9479-d4f17c49be88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Vol Adjusted Return_x</th>\n",
       "      <th>Index1</th>\n",
       "      <th>Vol Adjusted Return_y</th>\n",
       "      <th>Index2</th>\n",
       "      <th>average_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>APH</td>\n",
       "      <td>2.399607</td>\n",
       "      <td>13</td>\n",
       "      <td>1.518146</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CNP</td>\n",
       "      <td>2.773074</td>\n",
       "      <td>6</td>\n",
       "      <td>1.180759</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FHI</td>\n",
       "      <td>2.599810</td>\n",
       "      <td>9</td>\n",
       "      <td>1.185187</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TPR</td>\n",
       "      <td>4.498198</td>\n",
       "      <td>0</td>\n",
       "      <td>0.983924</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SXT</td>\n",
       "      <td>2.238709</td>\n",
       "      <td>19</td>\n",
       "      <td>1.578279</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Ticker  Vol Adjusted Return_x  Index1  Vol Adjusted Return_y  Index2  \\\n",
       "0    APH               2.399607      13               1.518146       2   \n",
       "1    CNP               2.773074       6               1.180759       9   \n",
       "2    FHI               2.599810       9               1.185187       8   \n",
       "3    TPR               4.498198       0               0.983924      19   \n",
       "4    SXT               2.238709      19               1.578279       1   \n",
       "\n",
       "   average_rank  \n",
       "0            15  \n",
       "1            15  \n",
       "2            17  \n",
       "3            19  \n",
       "4            20  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sort_values('average_rank', ascending=True)\n",
    "\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Create a csv file with the results\n",
    "df.to_csv(\"Momentum Screen Results.csv\", index=False) # set index = to false, or else it'll create a column with index\n",
    "df.head()\n",
    "\n",
    "\n",
    "###############"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477c1f59",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Convexity of Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "145390f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#only keep first 100 rows of the Momentum Screen Results \n",
    "df1 = df1.iloc[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2d0e9d66",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error retrieving data for FOX: 'Adj Close'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error retrieving data for FOXA: 'Adj Close'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error retrieving data for WELL: 'Adj Close'\n",
      "Error retrieving data for NI: 'Adj Close'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error retrieving data for T: 'Adj Close'\n",
      "Error retrieving data for SFM: 'Adj Close'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error retrieving data for PM: 'Adj Close'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error retrieving data for NFG: 'Adj Close'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error retrieving data for VTR: 'Adj Close'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error retrieving data for TMUS: 'Adj Close'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error retrieving data for KMI: 'Adj Close'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error retrieving data for DTM: 'Adj Close'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error retrieving data for BK: 'Adj Close'\n",
      "Error retrieving data for WMB: 'Adj Close'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error retrieving data for ETR: 'Adj Close'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error retrieving data for HWM: 'Adj Close'\n",
      "Error retrieving data for BSX: 'Adj Close'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error retrieving data for UNM: 'Adj Close'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error retrieving data for K: 'Adj Close'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error retrieving data for RTX: 'Adj Close'\n",
      "Error retrieving data for AEE: 'Adj Close'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error retrieving data for MMM: 'Adj Close'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error retrieving data for MO: 'Adj Close'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error retrieving data for EVRG: 'Adj Close'\n",
      "Error retrieving data for EXLS: 'Adj Close'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error retrieving data for BRO: 'Adj Close'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error retrieving data for OGE: 'Adj Close'\n",
      "Error retrieving data for FI: 'Adj Close'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error retrieving data for ACIW: 'Adj Close'\n",
      "Error retrieving data for ORI: 'Adj Close'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error retrieving data for XEL: 'Adj Close'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error retrieving data for WEC: 'Adj Close'\n",
      "Error retrieving data for PNW: 'Adj Close'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error retrieving data for ATO: 'Adj Close'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error retrieving data for CNO: 'Adj Close'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error retrieving data for PPL: 'Adj Close'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error retrieving data for GILD: 'Adj Close'\n",
      "Error retrieving data for WMT: 'Adj Close'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error retrieving data for LNT: 'Adj Close'\n",
      "Error retrieving data for IBKR: 'Adj Close'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error retrieving data for CMS: 'Adj Close'\n",
      "Error retrieving data for G: 'Adj Close'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error retrieving data for SO: 'Adj Close'\n",
      "Error retrieving data for NFLX: 'Adj Close'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error retrieving data for IDA: 'Adj Close'\n",
      "Error retrieving data for ICE: 'Adj Close'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error retrieving data for DUK: 'Adj Close'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error retrieving data for GLW: 'Adj Close'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error retrieving data for AEP: 'Adj Close'\n",
      "Error retrieving data for EPR: 'Adj Close'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error retrieving data for IRT: 'Adj Close'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error retrieving data for RCL: 'Adj Close'\n",
      "Error retrieving data for EXEL: 'Adj Close'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error retrieving data for FICO: 'Adj Close'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error retrieving data for SR: 'Adj Close'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error retrieving data for RSG: 'Adj Close'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error retrieving data for CME: 'Adj Close'\n",
      "Error retrieving data for ALE: 'Adj Close'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error retrieving data for SRCL: 'Adj Close'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error retrieving data for COKE: 'Adj Close'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error retrieving data for PGR: 'Adj Close'\n",
      "Error retrieving data for TTWO: 'Adj Close'\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[92], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m Ticker \u001b[38;5;129;01min\u001b[39;00m df1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTicker\u001b[39m\u001b[38;5;124m'\u001b[39m]:  \u001b[38;5;66;03m# Iterate over the 'Ticker' column\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m      9\u001b[0m         \u001b[38;5;66;03m# Download 2 years of historical data\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m         data \u001b[38;5;241m=\u001b[39m yf\u001b[38;5;241m.\u001b[39mdownload(Ticker, period\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2y\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     12\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m data\u001b[38;5;241m.\u001b[39mempty \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m252\u001b[39m:  \u001b[38;5;66;03m# Check if data is insufficient\u001b[39;00m\n\u001b[0;32m     13\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInsufficient data for ticker: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mTicker\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\yfinance\\utils.py:104\u001b[0m, in \u001b[0;36mlog_indent_decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    101\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEntering \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m()\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m IndentationContext():\n\u001b[1;32m--> 104\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    106\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExiting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m()\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\yfinance\\multi.py:162\u001b[0m, in \u001b[0;36mdownload\u001b[1;34m(tickers, start, end, actions, threads, ignore_tz, group_by, auto_adjust, back_adjust, repair, keepna, progress, period, interval, prepost, proxy, rounding, timeout, session, multi_level_index)\u001b[0m\n\u001b[0;32m    155\u001b[0m         _download_one_threaded(ticker, period\u001b[38;5;241m=\u001b[39mperiod, interval\u001b[38;5;241m=\u001b[39minterval,\n\u001b[0;32m    156\u001b[0m                                start\u001b[38;5;241m=\u001b[39mstart, end\u001b[38;5;241m=\u001b[39mend, prepost\u001b[38;5;241m=\u001b[39mprepost,\n\u001b[0;32m    157\u001b[0m                                actions\u001b[38;5;241m=\u001b[39mactions, auto_adjust\u001b[38;5;241m=\u001b[39mauto_adjust,\n\u001b[0;32m    158\u001b[0m                                back_adjust\u001b[38;5;241m=\u001b[39mback_adjust, repair\u001b[38;5;241m=\u001b[39mrepair, keepna\u001b[38;5;241m=\u001b[39mkeepna,\n\u001b[0;32m    159\u001b[0m                                progress\u001b[38;5;241m=\u001b[39m(progress \u001b[38;5;129;01mand\u001b[39;00m i \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m), proxy\u001b[38;5;241m=\u001b[39mproxy,\n\u001b[0;32m    160\u001b[0m                                rounding\u001b[38;5;241m=\u001b[39mrounding, timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(shared\u001b[38;5;241m.\u001b[39m_DFS) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(tickers):\n\u001b[1;32m--> 162\u001b[0m         _time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[0;32m    163\u001b[0m \u001b[38;5;66;03m# download synchronously\u001b[39;00m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, ticker \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tickers):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Collect rows in a list for concatenation\n",
    "rows_to_add_4 = []\n",
    "\n",
    "# Initialize a results DataFrame\n",
    "results_df = pd.DataFrame(columns=['Ticker', 'Convexity Ratio'])\n",
    "\n",
    "for Ticker in df1['Ticker']:  # Iterate over the 'Ticker' column\n",
    "    try:\n",
    "        # Download 2 years of historical data\n",
    "        data = yf.download(Ticker, period='2y')\n",
    "        \n",
    "        if data.empty or len(data) < 252:  # Check if data is insufficient\n",
    "            raise ValueError(f\"Insufficient data for ticker: {Ticker}\")\n",
    "        \n",
    "        # Create a DataFrame for returns\n",
    "        df = pd.DataFrame()\n",
    "        df['Return'] = data['Adj Close'].pct_change()\n",
    "\n",
    "        # Calculate the slope using a rolling window\n",
    "        window = 50  # Adjust window size as needed\n",
    "        df['Slope'] = df['Return'].rolling(window).apply(\n",
    "            lambda x: np.polyfit(np.arange(len(x)), x, 1)[0], raw=True\n",
    "        )\n",
    "\n",
    "        # Compute the second derivative of the slope\n",
    "        df['Second_Derivative'] = df['Slope'].diff()\n",
    "\n",
    "        # Calculate the convexity ratio\n",
    "        df['Convexity_Ratio'] = df['Second_Derivative'] / df['Slope']\n",
    "        \n",
    "        # Extract the most recent convexity ratio\n",
    "        convexity_ratio = df['Convexity_Ratio'].iloc[-1]\n",
    "        \n",
    "        # Add the result to the list\n",
    "        rows_to_add_4.append({'Ticker': Ticker, 'Convexity Ratio': convexity_ratio})\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving data for {Ticker}: {str(e)}\")\n",
    "        \n",
    "# Concatenate all rows into the DataFrame at once\n",
    "results_df = pd.concat([pd.DataFrame(rows_to_add_4)], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6f912e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = results_df.sort_values(by='Convexity Ratio', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "bc140635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Convexity Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>MRK</td>\n",
       "      <td>7.440757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>INTC</td>\n",
       "      <td>3.696518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>PEP</td>\n",
       "      <td>2.642901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>TXN</td>\n",
       "      <td>1.623321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>XOM</td>\n",
       "      <td>1.375793</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ticker  Convexity Ratio\n",
       "46    MRK         7.440757\n",
       "48   INTC         3.696518\n",
       "44    PEP         2.642901\n",
       "24    TXN         1.623321\n",
       "20    XOM         1.375793"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a3dc2896",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a new csv file with our FIP results\n",
    "df2.to_csv('Convexity_Results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987ca273",
   "metadata": {},
   "source": [
    "# Convexity Based on Quadratic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "4bc4d280",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.iloc[:400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "526bb229-9c5f-44e3-91e0-58008e4595d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  400 of 400 completed\n"
     ]
    }
   ],
   "source": [
    "rows_to_add_2 = []\n",
    "\n",
    "# Initialize an empty DataFrame to store results\n",
    "df_convexity = pd.DataFrame(columns=['Ticker', 'Convexity Score'])\n",
    "\n",
    "# Get tickers from df['Ticker'] list\n",
    "tickers = df['Ticker'].tolist()\n",
    "\n",
    "# Batch download 2 years of data for all tickers at once\n",
    "data = yf.download(tickers, period='2y', group_by='ticker', threads=True, auto_adjust=False)\n",
    "\n",
    "for ticker in tickers:\n",
    "    try:\n",
    "        # Retrieve individual ticker data from multi-ticker DataFrame\n",
    "        ticker_data = data[ticker].copy()\n",
    "\n",
    "        # Keep only last 252 rows... 252 trading days\n",
    "        ticker_data = ticker_data.tail(252)\n",
    "\n",
    "        # Ensure there is sufficient data\n",
    "        if ticker_data.empty or len(ticker_data) < 252:  \n",
    "            raise ValueError(f\"Insufficient data for ticker: {ticker}\")\n",
    "        \n",
    "        # Calculate daily returns (percentage change)\n",
    "        ticker_data['Return'] = ticker_data['Close'].pct_change() * 100\n",
    "\n",
    "        # Drop the first row since the return for the first day is NaN\n",
    "        ticker_data.dropna(inplace=True)\n",
    "        \n",
    "        # Create an ordinal time variable (index of the data)\n",
    "        ticker_data.loc[:, 'Time'] = np.arange(len(ticker_data))\n",
    "        \n",
    "        # Prepare the independent variables (Time and Time^2 for quadratic regression)\n",
    "        X = np.vstack([ticker_data['Time'], ticker_data['Time']**2]).T\n",
    "        y = ticker_data['Return'].values\n",
    "        \n",
    "        # Perform a quadratic regression\n",
    "        model = LinearRegression().fit(X, y)\n",
    "        \n",
    "        # The convexity is the coefficient of the squared time term\n",
    "        convexity = model.coef_[1]  # This is the coefficient of Time^2 (quadratic term)\n",
    "        \n",
    "        # Add the result to the list\n",
    "        rows_to_add_2.append({'Ticker': ticker, 'Convexity Score': convexity})\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving data for {ticker}: {str(e)}\")\n",
    "\n",
    "# Concatenate all rows into the DataFrame at once\n",
    "df_convexity = pd.concat([pd.DataFrame(rows_to_add_2)], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "ee3501da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Convexity Score</th>\n",
       "      <th>Index3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LWAY</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RIGL</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XMTR</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UEC</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>YOU</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Ticker  Convexity Score  Index3\n",
       "0   LWAY         0.000160       0\n",
       "1   RIGL         0.000158       1\n",
       "2   XMTR         0.000148       2\n",
       "3    UEC         0.000134       3\n",
       "4    YOU         0.000128       4"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_convexity = df_convexity.sort_values('Convexity Score', ascending=False)\n",
    "df_convexity.reset_index(drop=True, inplace=True)\n",
    "df_convexity.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "79469461",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_convexity.to_csv(\"Convexity_Score_Quadratic_Method.csv\")\n",
    "\n",
    "\n",
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b20760",
   "metadata": {},
   "source": [
    "# Momentum Quality - FIP (Frog in the Pan Score)\n",
    "\n",
    "ID or FIP Score\n",
    "ID = sign x [% Negative - % Positive]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "71088c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keep first 400 rows of the Momentum Screen Results\n",
    "df = df.iloc[:400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "6a2dcab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a blank dataframe with the appropriate columns\n",
    "df_FIP = pd.DataFrame(columns=['Ticker', 'FIP_Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "7f286388-ab39-4f3e-bc84-23d6ca56c298",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  391 of 391 completed\n"
     ]
    }
   ],
   "source": [
    "rows_to_add_3 = []\n",
    "\n",
    "# Get list of tickers from df\n",
    "tickers = df['Ticker'].tolist()\n",
    "\n",
    "# Batch download 2 years of data for all tickers at once\n",
    "data = yf.download(tickers, period='2y', group_by='ticker', threads=True, auto_adjust=False)\n",
    "\n",
    "for Ticker in tickers:  # Iterate over the 'ticker' column in df\n",
    "    try:\n",
    "        # Retrieve individual ticker data from multi-ticker DataFrame\n",
    "        ticker_data = data[Ticker].copy()\n",
    "        ticker_data = ticker_data.tail(252)  # Use only last 252 rows... for 252 trading days\n",
    "\n",
    "        if ticker_data.empty or len(ticker_data) < 252:  # Check if data is insufficient\n",
    "            raise ValueError(f\"Insufficient data for ticker: {Ticker}\")\n",
    "        \n",
    "        ticker_data['Percent Return'] = (ticker_data['Close'].pct_change()) * 100\n",
    "\n",
    "        if ticker_data['Percent Return'].cumsum().iat[-1] > 0:\n",
    "            sign = 1\n",
    "        elif ticker_data['Percent Return'].cumsum().iat[-1] < 0:\n",
    "            sign = -1\n",
    "        else:\n",
    "            sign = 0\n",
    "\n",
    "        positive_days = (ticker_data['Percent Return'] > 0).sum()\n",
    "        negative_days = (ticker_data['Percent Return'] < 0).sum()\n",
    "        flat_days = (ticker_data['Percent Return'] == 0).sum()\n",
    "        pct_positive = round(positive_days / len(ticker_data), 4)\n",
    "        pct_negative = round(negative_days / len(ticker_data), 4)\n",
    "        FIP_Score = round(sign * (pct_negative - pct_positive), 4)\n",
    "\n",
    "        # Add the result to the list\n",
    "        rows_to_add_3.append({'Ticker': Ticker, 'FIP Score': FIP_Score})\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving data for {Ticker}: {str(e)}\")\n",
    "\n",
    "df_FIP = pd.concat([pd.DataFrame(rows_to_add_3)], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "3a7352bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>FIP Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DTE</td>\n",
       "      <td>-0.2381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NDAQ</td>\n",
       "      <td>-0.2301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CW</td>\n",
       "      <td>-0.2222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GL</td>\n",
       "      <td>-0.2103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EVRG</td>\n",
       "      <td>-0.2024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Ticker  FIP Score\n",
       "0    DTE    -0.2381\n",
       "1   NDAQ    -0.2301\n",
       "2     CW    -0.2222\n",
       "3     GL    -0.2103\n",
       "4   EVRG    -0.2024"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_FIP = df_FIP.sort_values('FIP Score', ascending=True) # ascending = True since the best scores are negative\n",
    "df_FIP.reset_index(drop=True, inplace=True)\n",
    "df_FIP.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "aa493619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new csv file with our FIP results\n",
    "df_FIP.to_csv('Momentum_FIP_Results.csv', index=False)\n",
    "\n",
    "\n",
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ce12bc",
   "metadata": {},
   "source": [
    "# Combine Dataframes and Rank Tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "9f6a30e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create column of index #\n",
    "df['index_vol_rank'] = df.index #vol adjusted returns df\n",
    "\n",
    "#Create column of index #\n",
    "df_FIP['index_fip_rank'] = df_FIP.index # FIP df\n",
    "\n",
    "# create column of index # \n",
    "#df_convexity['Index3'] = df_convexity.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "079f383a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>FIP Score</th>\n",
       "      <th>index_fip_rank</th>\n",
       "      <th>Vol Adjusted Return_x</th>\n",
       "      <th>Index1</th>\n",
       "      <th>Vol Adjusted Return_y</th>\n",
       "      <th>Index2</th>\n",
       "      <th>average_rank</th>\n",
       "      <th>index_vol_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DTE</td>\n",
       "      <td>-0.2381</td>\n",
       "      <td>0</td>\n",
       "      <td>1.038812</td>\n",
       "      <td>150</td>\n",
       "      <td>0.770732</td>\n",
       "      <td>55</td>\n",
       "      <td>205</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NDAQ</td>\n",
       "      <td>-0.2301</td>\n",
       "      <td>1</td>\n",
       "      <td>2.172501</td>\n",
       "      <td>22</td>\n",
       "      <td>0.585190</td>\n",
       "      <td>92</td>\n",
       "      <td>114</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CW</td>\n",
       "      <td>-0.2222</td>\n",
       "      <td>2</td>\n",
       "      <td>2.281018</td>\n",
       "      <td>17</td>\n",
       "      <td>0.973420</td>\n",
       "      <td>22</td>\n",
       "      <td>39</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GL</td>\n",
       "      <td>-0.2103</td>\n",
       "      <td>3</td>\n",
       "      <td>2.128719</td>\n",
       "      <td>26</td>\n",
       "      <td>0.443613</td>\n",
       "      <td>130</td>\n",
       "      <td>156</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EVRG</td>\n",
       "      <td>-0.2024</td>\n",
       "      <td>4</td>\n",
       "      <td>1.548051</td>\n",
       "      <td>67</td>\n",
       "      <td>0.690504</td>\n",
       "      <td>66</td>\n",
       "      <td>133</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Ticker  FIP Score  index_fip_rank  Vol Adjusted Return_x  Index1  \\\n",
       "0    DTE    -0.2381               0               1.038812     150   \n",
       "1   NDAQ    -0.2301               1               2.172501      22   \n",
       "2     CW    -0.2222               2               2.281018      17   \n",
       "3     GL    -0.2103               3               2.128719      26   \n",
       "4   EVRG    -0.2024               4               1.548051      67   \n",
       "\n",
       "   Vol Adjusted Return_y  Index2  average_rank  index_vol_rank  \n",
       "0               0.770732      55           205              69  \n",
       "1               0.585190      92           114              30  \n",
       "2               0.973420      22            39               7  \n",
       "3               0.443613     130           156              52  \n",
       "4               0.690504      66           133              43  "
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform an inner join to include only matching tickers\n",
    "merged = pd.merge(df_FIP, df, on='Ticker', how='inner')\n",
    "\n",
    "merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84790d2f",
   "metadata": {},
   "source": [
    "### Next cell is only necessary if adding a third filter to the ranking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "aa2f61cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the result with the third DataFrame\n",
    "merged = pd.merge(merged, df_convexity, on='Ticker', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5516d68-2cdf-46bf-8108-07512b2a9939",
   "metadata": {},
   "source": [
    "### Proceed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "bcd615b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the score (sum of indices)\n",
    "\n",
    "#merged['Score'] = merged['index_vol_rank'] + merged['index_fip_rank'] + merged['Index3']\n",
    "merged['Score'] = merged['index_vol_rank'] + merged['index_fip_rank']\n",
    "\n",
    "# Sort the result by the score\n",
    "sorted_df = merged.sort_values('Score', ascending=True)\n",
    "# Select relevant columns for the output\n",
    "result = sorted_df[['Ticker', 'Score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "aa269535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CW</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>HWM</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CME</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DASH</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CAH</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ticker  Score\n",
       "2      CW      9\n",
       "15    HWM     20\n",
       "7     CME     20\n",
       "9    DASH     20\n",
       "13    CAH     21"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "70045d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv(\"Momentum_Ranked.csv\",index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#####"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d9c846-cbc3-46ad-a653-9238b1b2d1d0",
   "metadata": {},
   "source": [
    "# Risk-Parity Volatility Targetting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c1afa1-41f7-4286-8737-3f9cba5f1d27",
   "metadata": {},
   "source": [
    "This methodology transforms a set of screened tickers into a riskcontrolled portfolio. By estimating each assets historical volatility and using inversevolatility weighting, the process allocates more capital to steadier names while reducing exposure to highly volatile ones. The final scaling step ensures that the entire portfolio is expected to experience a predefined annualised volatility (e.g. 20%), giving you a consistent risk profile regardless of market regime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "6ed80d48-080d-4a8b-b5d8-d1554731a7e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CW</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>HWM</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CME</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DASH</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CAH</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PM</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>GE</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>BK</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>FHI</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NDAQ</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>WELL</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>EME</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>VRSN</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>CNP</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EVRG</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>ORCL</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>APH</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>T</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GL</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>DY</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NI</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DTE</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>WWD</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>ATO</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>TTWO</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>CSCO</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>IBKR</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>ICE</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>GILD</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>NFG</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>SCHW</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>ETR</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>GLW</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>MO</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>STT</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>JBL</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>UGI</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>TRMB</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>NFLX</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>EBAY</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>WDC</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>TPR</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>FFIV</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>ALLE</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>NVDA</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>RTX</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>CMS</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>L</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>JPM</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Ticker  Score\n",
       "2       CW      9\n",
       "15     HWM     20\n",
       "7      CME     20\n",
       "9     DASH     20\n",
       "13     CAH     21\n",
       "6       PM     24\n",
       "16      GE     25\n",
       "10      BK     29\n",
       "28     FHI     30\n",
       "1     NDAQ     31\n",
       "19    WELL     33\n",
       "21     EME     41\n",
       "22    VRSN     43\n",
       "43     CNP     44\n",
       "4     EVRG     47\n",
       "36    ORCL     51\n",
       "53     APH     53\n",
       "23       T     54\n",
       "3       GL     55\n",
       "34      DY     56\n",
       "8       NI     57\n",
       "0      DTE     69\n",
       "54     WWD     70\n",
       "39     ATO     73\n",
       "32    TTWO     74\n",
       "38    CSCO     86\n",
       "5     IBKR     88\n",
       "55     ICE     90\n",
       "14    GILD     90\n",
       "88     NFG     94\n",
       "59    SCHW     96\n",
       "42     ETR     98\n",
       "69     GLW    101\n",
       "79      MO    105\n",
       "18     STT    106\n",
       "97     JBL    109\n",
       "70     UGI    110\n",
       "24    TRMB    110\n",
       "66    NFLX    110\n",
       "102   EBAY    112\n",
       "90     WDC    114\n",
       "115    TPR    118\n",
       "17    FFIV    119\n",
       "68    ALLE    121\n",
       "84    NVDA    122\n",
       "64     RTX    124\n",
       "85    MSFT    130\n",
       "29     CMS    134\n",
       "12       L    138\n",
       "30     JPM    138"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keep only the top 50 equities\n",
    "result = result.head(50)\n",
    "result.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d652b7-4bbf-4728-95ce-4287713a8a9a",
   "metadata": {},
   "source": [
    "### Risk Parity Light*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "b54a5f46-6dda-4db8-99bd-752de2d9cdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a blank DataFrame to store the results\n",
    "df_voltarget = pd.DataFrame(columns=['Ticker', 'Volatility', 'Weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "28e04396-5f6c-4775-95e0-c908a25d183e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  50 of 50 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Volatility</th>\n",
       "      <th>Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CW</td>\n",
       "      <td>0.320931</td>\n",
       "      <td>1.561526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HWM</td>\n",
       "      <td>0.302508</td>\n",
       "      <td>1.656626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CME</td>\n",
       "      <td>0.171384</td>\n",
       "      <td>2.924088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DASH</td>\n",
       "      <td>0.296250</td>\n",
       "      <td>1.691622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CAH</td>\n",
       "      <td>0.172242</td>\n",
       "      <td>2.909525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PM</td>\n",
       "      <td>0.315714</td>\n",
       "      <td>1.587330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GE</td>\n",
       "      <td>0.222672</td>\n",
       "      <td>2.250587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BK</td>\n",
       "      <td>0.160503</td>\n",
       "      <td>3.122317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>FHI</td>\n",
       "      <td>0.186644</td>\n",
       "      <td>2.685015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NDAQ</td>\n",
       "      <td>0.211823</td>\n",
       "      <td>2.365849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>WELL</td>\n",
       "      <td>0.208595</td>\n",
       "      <td>2.402461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>EME</td>\n",
       "      <td>0.330644</td>\n",
       "      <td>1.515657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>VRSN</td>\n",
       "      <td>0.373930</td>\n",
       "      <td>1.340202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CNP</td>\n",
       "      <td>0.187231</td>\n",
       "      <td>2.676593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>EVRG</td>\n",
       "      <td>0.176598</td>\n",
       "      <td>2.837753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ORCL</td>\n",
       "      <td>0.371198</td>\n",
       "      <td>1.350066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>APH</td>\n",
       "      <td>0.233644</td>\n",
       "      <td>2.144893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>T</td>\n",
       "      <td>0.183540</td>\n",
       "      <td>2.730431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>GL</td>\n",
       "      <td>0.317593</td>\n",
       "      <td>1.577937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>DY</td>\n",
       "      <td>0.273443</td>\n",
       "      <td>1.832715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NI</td>\n",
       "      <td>0.193792</td>\n",
       "      <td>2.585975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>DTE</td>\n",
       "      <td>0.168116</td>\n",
       "      <td>2.980934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>WWD</td>\n",
       "      <td>0.249160</td>\n",
       "      <td>2.011326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ATO</td>\n",
       "      <td>0.202729</td>\n",
       "      <td>2.471985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>TTWO</td>\n",
       "      <td>0.201195</td>\n",
       "      <td>2.490833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>CSCO</td>\n",
       "      <td>0.178735</td>\n",
       "      <td>2.803831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>IBKR</td>\n",
       "      <td>0.337786</td>\n",
       "      <td>1.483610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ICE</td>\n",
       "      <td>0.128409</td>\n",
       "      <td>3.902703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>GILD</td>\n",
       "      <td>0.308931</td>\n",
       "      <td>1.622179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NFG</td>\n",
       "      <td>0.219526</td>\n",
       "      <td>2.282834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>SCHW</td>\n",
       "      <td>0.174944</td>\n",
       "      <td>2.864585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>ETR</td>\n",
       "      <td>0.176270</td>\n",
       "      <td>2.843045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>GLW</td>\n",
       "      <td>0.378466</td>\n",
       "      <td>1.324141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>MO</td>\n",
       "      <td>0.194904</td>\n",
       "      <td>2.571230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>STT</td>\n",
       "      <td>0.289599</td>\n",
       "      <td>1.730468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>JBL</td>\n",
       "      <td>0.300922</td>\n",
       "      <td>1.665355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>UGI</td>\n",
       "      <td>0.195994</td>\n",
       "      <td>2.556925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>TRMB</td>\n",
       "      <td>0.198619</td>\n",
       "      <td>2.523135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>NFLX</td>\n",
       "      <td>0.279525</td>\n",
       "      <td>1.792835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>EBAY</td>\n",
       "      <td>0.537045</td>\n",
       "      <td>0.933148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>WDC</td>\n",
       "      <td>0.382173</td>\n",
       "      <td>1.311298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>TPR</td>\n",
       "      <td>0.347358</td>\n",
       "      <td>1.442724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>FFIV</td>\n",
       "      <td>0.261746</td>\n",
       "      <td>1.914612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>ALLE</td>\n",
       "      <td>0.277702</td>\n",
       "      <td>1.804602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>NVDA</td>\n",
       "      <td>0.287000</td>\n",
       "      <td>1.746141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>RTX</td>\n",
       "      <td>0.206279</td>\n",
       "      <td>2.429438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>0.178378</td>\n",
       "      <td>2.809445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>CMS</td>\n",
       "      <td>0.165887</td>\n",
       "      <td>3.020983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>L</td>\n",
       "      <td>0.163609</td>\n",
       "      <td>3.063043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>JPM</td>\n",
       "      <td>0.173176</td>\n",
       "      <td>2.893838</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ticker  Volatility    Weight\n",
       "0      CW    0.320931  1.561526\n",
       "1     HWM    0.302508  1.656626\n",
       "2     CME    0.171384  2.924088\n",
       "3    DASH    0.296250  1.691622\n",
       "4     CAH    0.172242  2.909525\n",
       "5      PM    0.315714  1.587330\n",
       "6      GE    0.222672  2.250587\n",
       "7      BK    0.160503  3.122317\n",
       "8     FHI    0.186644  2.685015\n",
       "9    NDAQ    0.211823  2.365849\n",
       "10   WELL    0.208595  2.402461\n",
       "11    EME    0.330644  1.515657\n",
       "12   VRSN    0.373930  1.340202\n",
       "13    CNP    0.187231  2.676593\n",
       "14   EVRG    0.176598  2.837753\n",
       "15   ORCL    0.371198  1.350066\n",
       "16    APH    0.233644  2.144893\n",
       "17      T    0.183540  2.730431\n",
       "18     GL    0.317593  1.577937\n",
       "19     DY    0.273443  1.832715\n",
       "20     NI    0.193792  2.585975\n",
       "21    DTE    0.168116  2.980934\n",
       "22    WWD    0.249160  2.011326\n",
       "23    ATO    0.202729  2.471985\n",
       "24   TTWO    0.201195  2.490833\n",
       "25   CSCO    0.178735  2.803831\n",
       "26   IBKR    0.337786  1.483610\n",
       "27    ICE    0.128409  3.902703\n",
       "28   GILD    0.308931  1.622179\n",
       "29    NFG    0.219526  2.282834\n",
       "30   SCHW    0.174944  2.864585\n",
       "31    ETR    0.176270  2.843045\n",
       "32    GLW    0.378466  1.324141\n",
       "33     MO    0.194904  2.571230\n",
       "34    STT    0.289599  1.730468\n",
       "35    JBL    0.300922  1.665355\n",
       "36    UGI    0.195994  2.556925\n",
       "37   TRMB    0.198619  2.523135\n",
       "38   NFLX    0.279525  1.792835\n",
       "39   EBAY    0.537045  0.933148\n",
       "40    WDC    0.382173  1.311298\n",
       "41    TPR    0.347358  1.442724\n",
       "42   FFIV    0.261746  1.914612\n",
       "43   ALLE    0.277702  1.804602\n",
       "44   NVDA    0.287000  1.746141\n",
       "45    RTX    0.206279  2.429438\n",
       "46   MSFT    0.178378  2.809445\n",
       "47    CMS    0.165887  3.020983\n",
       "48      L    0.163609  3.063043\n",
       "49    JPM    0.173176  2.893838"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Collect rows in a list for concatenation\n",
    "rows_to_add = []\n",
    "\n",
    "# Extract tickers from the df\n",
    "tickers = result['Ticker'].dropna().tolist()\n",
    "\n",
    "# Download 2 years of data for all tickers\n",
    "data = yf.download(tickers, period='2y', group_by='ticker', threads=True, auto_adjust=False)\n",
    "\n",
    "# Prepare a DataFrame to store daily returns\n",
    "returns_df = pd.DataFrame()\n",
    "blended_vol_dict = {}\n",
    "\n",
    "# Loop through each ticker\n",
    "for ticker in tickers:\n",
    "    try:\n",
    "        # Retrieve individual ticker data\n",
    "        ticker_data = data[ticker].copy()\n",
    "\n",
    "        # Ensure sufficient history\n",
    "        if ticker_data.empty or len(ticker_data) < 252:\n",
    "            raise ValueError(f\"Insufficient data for ticker: {ticker}\")\n",
    "\n",
    "        # Calculate daily returns\n",
    "        ticker_data['Daily Return'] = ticker_data['Close'].pct_change()\n",
    "\n",
    "        # Store daily returns\n",
    "        returns_df[ticker] = ticker_data['Daily Return']\n",
    "\n",
    "        # Calculate annualized realized volatilities\n",
    "        vol_21 = ticker_data['Daily Return'].rolling(21).std().iloc[-1] * np.sqrt(252) # one month vol\n",
    "        vol_126 = ticker_data['Daily Return'].rolling(63).std().iloc[-1] * np.sqrt(252) # 3 month vol\n",
    "        #vol_252 = ticker_data['Daily Return'].rolling(126).std().iloc[-1] * np.sqrt(252) # 1 year vol\n",
    "\n",
    "        # Equal-weighted blended vol\n",
    "        blended_vol = np.mean([vol_21, vol_126])\n",
    "\n",
    "        # Store in dict\n",
    "        blended_vol_dict[ticker] = blended_vol\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {ticker}: {e}\")\n",
    "\n",
    "# Drop rows w missing values\n",
    "returns_df = returns_df.dropna()\n",
    "\n",
    "# Convert to Series\n",
    "volatility = pd.Series(blended_vol_dict)\n",
    "\n",
    "# Compute inverse-volatility weights (raw weights before scaling)\n",
    "inverse_vol = 1 / volatility\n",
    "raw_weights = inverse_vol / inverse_vol.sum()\n",
    "\n",
    "# Compute annualized covariance matrix\n",
    "cov_matrix = returns_df.cov() * 252\n",
    "\n",
    "# Portfolio current volatility\n",
    "current_vol = np.sqrt(raw_weights.T @ cov_matrix @ raw_weights)\n",
    "\n",
    "# Target vol scaling\n",
    "target_vol = 0.15\n",
    "scaling_factor = target_vol / current_vol\n",
    "\n",
    "# Final weights after scaling\n",
    "final_weights = (raw_weights * scaling_factor) * 100\n",
    "\n",
    "# Build final output rows\n",
    "for ticker in final_weights.index:\n",
    "    rows_to_add.append({\n",
    "        'Ticker': ticker,\n",
    "        'Volatility': volatility[ticker],\n",
    "        'Weight': final_weights[ticker]\n",
    "    })\n",
    "\n",
    "# Final output DataFrame\n",
    "df_voltarget = pd.DataFrame(rows_to_add)\n",
    "\n",
    "df_voltarget.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0996b41d-b689-4a5b-b3b8-9ab1050df588",
   "metadata": {},
   "source": [
    "### Full Risk Parity and Volatility Targetting (Accounts for Correlations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "ef0d246c-9090-477a-b0fd-a93764e3c7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a blank DataFrame to store the results\n",
    "df_voltarget = pd.DataFrame(columns=['Ticker', 'Volatility', 'Weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "a9c0d1e3-b472-4b2a-b7df-a613e73232a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  50 of 50 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Volatility</th>\n",
       "      <th>Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CW</td>\n",
       "      <td>0.313156</td>\n",
       "      <td>1.756360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HWM</td>\n",
       "      <td>0.302401</td>\n",
       "      <td>1.367595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CME</td>\n",
       "      <td>0.171463</td>\n",
       "      <td>3.340483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DASH</td>\n",
       "      <td>0.288751</td>\n",
       "      <td>1.416659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CAH</td>\n",
       "      <td>0.170746</td>\n",
       "      <td>3.246620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PM</td>\n",
       "      <td>0.316088</td>\n",
       "      <td>3.351167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GE</td>\n",
       "      <td>0.222464</td>\n",
       "      <td>1.527086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BK</td>\n",
       "      <td>0.160687</td>\n",
       "      <td>2.065763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>FHI</td>\n",
       "      <td>0.186519</td>\n",
       "      <td>2.666943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NDAQ</td>\n",
       "      <td>0.211776</td>\n",
       "      <td>2.154816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>WELL</td>\n",
       "      <td>0.208647</td>\n",
       "      <td>2.911730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>EME</td>\n",
       "      <td>0.330624</td>\n",
       "      <td>1.459972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>VRSN</td>\n",
       "      <td>0.373886</td>\n",
       "      <td>3.148137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CNP</td>\n",
       "      <td>0.187726</td>\n",
       "      <td>3.175280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>EVRG</td>\n",
       "      <td>0.176558</td>\n",
       "      <td>3.212878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ORCL</td>\n",
       "      <td>0.371023</td>\n",
       "      <td>1.495602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>APH</td>\n",
       "      <td>0.232824</td>\n",
       "      <td>1.574964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>T</td>\n",
       "      <td>0.184503</td>\n",
       "      <td>3.429917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>GL</td>\n",
       "      <td>0.317615</td>\n",
       "      <td>1.755597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>DY</td>\n",
       "      <td>0.273673</td>\n",
       "      <td>1.557082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NI</td>\n",
       "      <td>0.194076</td>\n",
       "      <td>2.751626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>DTE</td>\n",
       "      <td>0.168041</td>\n",
       "      <td>3.129799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>WWD</td>\n",
       "      <td>0.248469</td>\n",
       "      <td>1.708130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ATO</td>\n",
       "      <td>0.203634</td>\n",
       "      <td>3.214663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>TTWO</td>\n",
       "      <td>0.200590</td>\n",
       "      <td>2.783774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>CSCO</td>\n",
       "      <td>0.178928</td>\n",
       "      <td>2.495393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>IBKR</td>\n",
       "      <td>0.337729</td>\n",
       "      <td>1.397851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ICE</td>\n",
       "      <td>0.128405</td>\n",
       "      <td>2.935982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>GILD</td>\n",
       "      <td>0.308917</td>\n",
       "      <td>3.345783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NFG</td>\n",
       "      <td>0.219540</td>\n",
       "      <td>2.818413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>SCHW</td>\n",
       "      <td>0.174911</td>\n",
       "      <td>1.867985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>ETR</td>\n",
       "      <td>0.176250</td>\n",
       "      <td>2.736590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>GLW</td>\n",
       "      <td>0.378490</td>\n",
       "      <td>1.750865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>MO</td>\n",
       "      <td>0.195015</td>\n",
       "      <td>3.448027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>STT</td>\n",
       "      <td>0.289280</td>\n",
       "      <td>1.644192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>JBL</td>\n",
       "      <td>0.300719</td>\n",
       "      <td>1.476006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>UGI</td>\n",
       "      <td>0.196418</td>\n",
       "      <td>2.254562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>TRMB</td>\n",
       "      <td>0.199450</td>\n",
       "      <td>1.334558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>NFLX</td>\n",
       "      <td>0.279479</td>\n",
       "      <td>2.447880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>EBAY</td>\n",
       "      <td>0.537158</td>\n",
       "      <td>2.782130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>WDC</td>\n",
       "      <td>0.382105</td>\n",
       "      <td>1.385505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>TPR</td>\n",
       "      <td>0.346743</td>\n",
       "      <td>1.432054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>FFIV</td>\n",
       "      <td>0.260880</td>\n",
       "      <td>2.083456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>ALLE</td>\n",
       "      <td>0.277845</td>\n",
       "      <td>2.429827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>NVDA</td>\n",
       "      <td>0.286959</td>\n",
       "      <td>1.522324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>RTX</td>\n",
       "      <td>0.205987</td>\n",
       "      <td>2.936481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>0.178517</td>\n",
       "      <td>2.734997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>CMS</td>\n",
       "      <td>0.166099</td>\n",
       "      <td>3.363042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>L</td>\n",
       "      <td>0.164036</td>\n",
       "      <td>2.708614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>JPM</td>\n",
       "      <td>0.173500</td>\n",
       "      <td>1.962255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ticker  Volatility    Weight\n",
       "0      CW    0.313156  1.756360\n",
       "1     HWM    0.302401  1.367595\n",
       "2     CME    0.171463  3.340483\n",
       "3    DASH    0.288751  1.416659\n",
       "4     CAH    0.170746  3.246620\n",
       "5      PM    0.316088  3.351167\n",
       "6      GE    0.222464  1.527086\n",
       "7      BK    0.160687  2.065763\n",
       "8     FHI    0.186519  2.666943\n",
       "9    NDAQ    0.211776  2.154816\n",
       "10   WELL    0.208647  2.911730\n",
       "11    EME    0.330624  1.459972\n",
       "12   VRSN    0.373886  3.148137\n",
       "13    CNP    0.187726  3.175280\n",
       "14   EVRG    0.176558  3.212878\n",
       "15   ORCL    0.371023  1.495602\n",
       "16    APH    0.232824  1.574964\n",
       "17      T    0.184503  3.429917\n",
       "18     GL    0.317615  1.755597\n",
       "19     DY    0.273673  1.557082\n",
       "20     NI    0.194076  2.751626\n",
       "21    DTE    0.168041  3.129799\n",
       "22    WWD    0.248469  1.708130\n",
       "23    ATO    0.203634  3.214663\n",
       "24   TTWO    0.200590  2.783774\n",
       "25   CSCO    0.178928  2.495393\n",
       "26   IBKR    0.337729  1.397851\n",
       "27    ICE    0.128405  2.935982\n",
       "28   GILD    0.308917  3.345783\n",
       "29    NFG    0.219540  2.818413\n",
       "30   SCHW    0.174911  1.867985\n",
       "31    ETR    0.176250  2.736590\n",
       "32    GLW    0.378490  1.750865\n",
       "33     MO    0.195015  3.448027\n",
       "34    STT    0.289280  1.644192\n",
       "35    JBL    0.300719  1.476006\n",
       "36    UGI    0.196418  2.254562\n",
       "37   TRMB    0.199450  1.334558\n",
       "38   NFLX    0.279479  2.447880\n",
       "39   EBAY    0.537158  2.782130\n",
       "40    WDC    0.382105  1.385505\n",
       "41    TPR    0.346743  1.432054\n",
       "42   FFIV    0.260880  2.083456\n",
       "43   ALLE    0.277845  2.429827\n",
       "44   NVDA    0.286959  1.522324\n",
       "45    RTX    0.205987  2.936481\n",
       "46   MSFT    0.178517  2.734997\n",
       "47    CMS    0.166099  3.363042\n",
       "48      L    0.164036  2.708614\n",
       "49    JPM    0.173500  1.962255"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Risk parity solver\n",
    "def solve_full_risk_parity(cov_matrix):\n",
    "    n = cov_matrix.shape[0]\n",
    "    init_w = np.ones(n) / n\n",
    "\n",
    "    def portfolio_risk_contributions(weights):\n",
    "        port_vol = np.sqrt(weights.T @ cov_matrix @ weights)\n",
    "        marginal_contribs = cov_matrix @ weights\n",
    "        risk_contribs = weights * marginal_contribs\n",
    "        return risk_contribs / port_vol\n",
    "\n",
    "    def objective(weights):\n",
    "        rc = portfolio_risk_contributions(weights)\n",
    "        return np.sum((rc - rc.mean())**2)\n",
    "\n",
    "    constraints = ({'type': 'eq', 'fun': lambda w: np.sum(w) - 1})\n",
    "    bounds = [(0, 1) for _ in range(n)]\n",
    "\n",
    "    result = minimize(objective, init_w, method='SLSQP', bounds=bounds, constraints=constraints)\n",
    "\n",
    "    if not result.success:\n",
    "        raise ValueError(\"Risk parity optimization failed:\", result.message)\n",
    "\n",
    "    return pd.Series(result.x, index=cov_matrix.columns)\n",
    "\n",
    "# Collect rows in a list for concatenation\n",
    "rows_to_add = []\n",
    "\n",
    "# Extract tickers from df\n",
    "tickers = result['Ticker'].dropna().tolist()\n",
    "\n",
    "# Download 2 years of data for all tickers\n",
    "data = yf.download(tickers, period='2y', group_by='ticker', threads=True, auto_adjust=False)\n",
    "\n",
    "# Prepare a DataFrame to store daily returns\n",
    "returns_df = pd.DataFrame()\n",
    "blended_vol_dict = {}\n",
    "\n",
    "# Loop through tickers\n",
    "for ticker in tickers:\n",
    "    try:\n",
    "        ticker_data = data[ticker].copy()\n",
    "\n",
    "        if ticker_data.empty or len(ticker_data) < 252:\n",
    "            raise ValueError(f\"Insufficient data for ticker: {ticker}\")\n",
    "\n",
    "        ticker_data['Daily Return'] = ticker_data['Close'].pct_change()\n",
    "        returns_df[ticker] = ticker_data['Daily Return']\n",
    "\n",
    "        vol_21 = ticker_data['Daily Return'].rolling(21).std().iloc[-1] * np.sqrt(252) # one month vol\n",
    "        vol_126 = ticker_data['Daily Return'].rolling(63).std().iloc[-1] * np.sqrt(252) # 3 month vol\n",
    "        blended_vol = np.mean([vol_21, vol_126])\n",
    "        blended_vol_dict[ticker] = blended_vol\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {ticker}: {e}\")\n",
    "\n",
    "# drop rows w nan's\n",
    "returns_df = returns_df.dropna()\n",
    "\n",
    "# convert to volatility series\n",
    "volatility = pd.Series(blended_vol_dict)\n",
    "\n",
    "# Covariance matrix (annualized)\n",
    "cov_matrix = returns_df.cov() * 252\n",
    "\n",
    "# Risk Parity Weights\n",
    "raw_weights = solve_full_risk_parity(cov_matrix)\n",
    "\n",
    "# Portfolio vol (full risk parity weights)\n",
    "current_vol = np.sqrt(raw_weights.T @ cov_matrix @ raw_weights)\n",
    "\n",
    "# Vo targeting\n",
    "target_vol = 0.15\n",
    "scaling_factor = target_vol / current_vol\n",
    "final_weights = (raw_weights * scaling_factor) * 100\n",
    "\n",
    "# Output DataFrame\n",
    "for ticker in final_weights.index:\n",
    "    rows_to_add.append({\n",
    "        'Ticker': ticker,\n",
    "        'Volatility': volatility[ticker],\n",
    "        'Weight': final_weights[ticker]\n",
    "    })\n",
    "\n",
    "df_voltarget = pd.DataFrame(rows_to_add)\n",
    "\n",
    "df_voltarget.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "58843b8f-c7b3-4854-8efd-42a1119364bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Portfolio Exposure:\n",
      "117.4974\n",
      "\n",
      "Average % Exposure:\n",
      "2.3499\n"
     ]
    }
   ],
   "source": [
    "print('Total Portfolio Exposure:')\n",
    "print(df_voltarget['Weight'].sum().round(4))\n",
    "print()\n",
    "print('Average % Exposure:')\n",
    "print(df_voltarget['Weight'].mean().round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "75925f79-15ba-46ce-a3f1-404178485e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save target portfolio into CSV file & txt. file\n",
    "\n",
    "df_voltarget.to_csv('Target Portfolio.csv')\n",
    "\n",
    "df_voltarget[['Ticker']].to_csv('Target_Portfolio.txt', sep='\\t', index=False) # Export only the 'Ticker' column to a text file\n",
    "\n",
    "\n",
    "######"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
