{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86772b6a",
   "metadata": {},
   "source": [
    "# Momentum Screener\n",
    "\n",
    "\n",
    "The gist of this methodology is essentially to:\n",
    "\n",
    "    1.) Penalize for Volatility\n",
    "    2.) Buy non-news driven momentum - FIP helps filter for this\n",
    "\n",
    "\n",
    "Process:\n",
    "\n",
    "1.) Omit top % decile of the most volatile stocks in our universe\n",
    "\n",
    "2.) 1yr/6month Volatiltiy Adjusted Returns: Calculate 1yr and 6month volatiltiy-adjusted returns and sort them highest to lowest - based on a combined 1yr & 6month score\n",
    "\n",
    "3.) FIP (Momentum Quality): Calculate FIP for the top 50% of the stocks from the vol-adjsuted reteurn screen\n",
    "\n",
    "4.) Rank Tickers: Calculate combined score based on the 1yr/6month vol-adjusted score and also the FIP score\n",
    "\n",
    "5.) Purchase the top 40-50 equities from the universe (or a % based)\n",
    "\n",
    "6.) Volatility Targetting: Volatility Targetted position sizing based on desired portfolio vol\n",
    "\n",
    "7.) Rebalance: Rebalance monthly OR rebalance based on EV > Cost of rebalancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e84fe66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import yfinance as yf\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19ea4528",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MSFT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GOOG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AMZN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TSLA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ticker\n",
       "0   AAPL\n",
       "1   MSFT\n",
       "2   GOOG\n",
       "3   AMZN\n",
       "4   TSLA"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp500_tickers = pd.read_csv('sp500_tickers.csv')  # Assuming you have a file of S&P500 tickers\n",
    "sp500_tickers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9d81c8-b552-49f7-810c-8e705f6a8bb7",
   "metadata": {},
   "source": [
    "# Omit Top Decile of Highest 1yr Volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "721719b5-60d8-4936-9b1d-57bb512e1353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a blank dataframe with the appropriate columns\n",
    "df = pd.DataFrame(columns=['Ticker', 'Historical Volatility'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de02298a-c806-4c82-8fc7-a2d118285d9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  848 of 848 completed\n",
      "\n",
      "9 Failed downloads:\n",
      "['RCM', 'DFS', 'CTLT', 'TPX', 'ENV', 'PDCO', 'MRO', 'NARI', 'AZPN']: YFPricesMissingError('possibly delisted; no price data found  (period=2y) (Yahoo error = \"No data found, symbol may be delisted\")')\n",
      "C:\\Users\\eabiz\\AppData\\Local\\Temp\\ipykernel_24852\\1293045128.py:20: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  ticker_data['Daily Return'] = ticker_data['Close'].pct_change()\n",
      "C:\\Users\\eabiz\\AppData\\Local\\Temp\\ipykernel_24852\\1293045128.py:20: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  ticker_data['Daily Return'] = ticker_data['Close'].pct_change()\n",
      "C:\\Users\\eabiz\\AppData\\Local\\Temp\\ipykernel_24852\\1293045128.py:20: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  ticker_data['Daily Return'] = ticker_data['Close'].pct_change()\n",
      "C:\\Users\\eabiz\\AppData\\Local\\Temp\\ipykernel_24852\\1293045128.py:20: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  ticker_data['Daily Return'] = ticker_data['Close'].pct_change()\n",
      "C:\\Users\\eabiz\\AppData\\Local\\Temp\\ipykernel_24852\\1293045128.py:20: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  ticker_data['Daily Return'] = ticker_data['Close'].pct_change()\n",
      "C:\\Users\\eabiz\\AppData\\Local\\Temp\\ipykernel_24852\\1293045128.py:20: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  ticker_data['Daily Return'] = ticker_data['Close'].pct_change()\n",
      "C:\\Users\\eabiz\\AppData\\Local\\Temp\\ipykernel_24852\\1293045128.py:20: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  ticker_data['Daily Return'] = ticker_data['Close'].pct_change()\n",
      "C:\\Users\\eabiz\\AppData\\Local\\Temp\\ipykernel_24852\\1293045128.py:20: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  ticker_data['Daily Return'] = ticker_data['Close'].pct_change()\n",
      "C:\\Users\\eabiz\\AppData\\Local\\Temp\\ipykernel_24852\\1293045128.py:20: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  ticker_data['Daily Return'] = ticker_data['Close'].pct_change()\n",
      "C:\\Users\\eabiz\\AppData\\Local\\Temp\\ipykernel_24852\\1293045128.py:20: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  ticker_data['Daily Return'] = ticker_data['Close'].pct_change()\n",
      "C:\\Users\\eabiz\\AppData\\Local\\Temp\\ipykernel_24852\\1293045128.py:20: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  ticker_data['Daily Return'] = ticker_data['Close'].pct_change()\n",
      "C:\\Users\\eabiz\\AppData\\Local\\Temp\\ipykernel_24852\\1293045128.py:20: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  ticker_data['Daily Return'] = ticker_data['Close'].pct_change()\n",
      "C:\\Users\\eabiz\\AppData\\Local\\Temp\\ipykernel_24852\\1293045128.py:20: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  ticker_data['Daily Return'] = ticker_data['Close'].pct_change()\n",
      "C:\\Users\\eabiz\\AppData\\Local\\Temp\\ipykernel_24852\\1293045128.py:20: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  ticker_data['Daily Return'] = ticker_data['Close'].pct_change()\n",
      "C:\\Users\\eabiz\\AppData\\Local\\Temp\\ipykernel_24852\\1293045128.py:20: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  ticker_data['Daily Return'] = ticker_data['Close'].pct_change()\n",
      "C:\\Users\\eabiz\\AppData\\Local\\Temp\\ipykernel_24852\\1293045128.py:20: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  ticker_data['Daily Return'] = ticker_data['Close'].pct_change()\n"
     ]
    }
   ],
   "source": [
    "# Collect rows in a list for concatenation\n",
    "rows_to_add = []\n",
    "\n",
    "# Convert tickers column to a list\n",
    "tickers = sp500_tickers['ticker'].tolist()\n",
    "\n",
    "# Batch download all tickers at once\n",
    "data = yf.download(tickers, period='2y', group_by='ticker', threads=True, auto_adjust=False)\n",
    "\n",
    "for ticker in tickers:  # Iterate over the 'ticker' list\n",
    "    try:\n",
    "        # Retrieve individual ticker data from multi-ticker DataFrame\n",
    "        ticker_data = data[ticker].copy()\n",
    "\n",
    "        # Check if data is insufficient\n",
    "        if ticker_data.empty or len(ticker_data) < 252:  \n",
    "            raise ValueError(f\"Insufficient data for ticker: {ticker}\") \n",
    "\n",
    "        # Calculate daily returns\n",
    "        ticker_data['Daily Return'] = ticker_data['Close'].pct_change()\n",
    "\n",
    "        # Rolling window for std dev (daily returns)\n",
    "        window = 252  \n",
    "\n",
    "        # Calculate rolling standard deviation of daily returns\n",
    "        ticker_data['Rolling_Std'] = ticker_data['Daily Return'].rolling(window).std()\n",
    "\n",
    "        # Annualize rolling standard deviation to get historical annual volatility\n",
    "        ticker_data['Rolling_Hist_Vol'] = ticker_data['Rolling_Std'] * np.sqrt(window)\n",
    "\n",
    "        # Retrieve the last value of Vol Adjusted Return\n",
    "        historical_vol = ticker_data['Rolling_Hist_Vol'].iat[-1]\n",
    "\n",
    "        # Add the result to the list\n",
    "        rows_to_add.append({'Ticker': ticker, 'Historical Volatility': historical_vol})\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving data for {ticker}: {str(e)}\")\n",
    "\n",
    "# Concatenate all rows into the DataFrame at once\n",
    "df = pd.concat([pd.DataFrame(rows_to_add)], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35278b70-acd9-4d87-8346-e7506e2de92c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Historical Volatility</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>WOLF</td>\n",
       "      <td>2.288332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>LUMN</td>\n",
       "      <td>1.266787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>SMCI</td>\n",
       "      <td>1.135844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>SEDG</td>\n",
       "      <td>1.125426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>RUN</td>\n",
       "      <td>1.062644</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Ticker  Historical Volatility\n",
       "516   WOLF               2.288332\n",
       "441   LUMN               1.266787\n",
       "753   SMCI               1.135844\n",
       "363   SEDG               1.125426\n",
       "685    RUN               1.062644"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sort_values('Historical Volatility', ascending=False) #highest Vol at the top\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2583f27f-875f-4ffe-8236-6213c4cc3d08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Historical Volatility</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>CNC</td>\n",
       "      <td>0.538774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NVDA</td>\n",
       "      <td>0.538194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>HBI</td>\n",
       "      <td>0.537267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>TER</td>\n",
       "      <td>0.537068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>844</th>\n",
       "      <td>OMCL</td>\n",
       "      <td>0.536058</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Ticker  Historical Volatility\n",
       "147    CNC               0.538774\n",
       "5     NVDA               0.538194\n",
       "829    HBI               0.537267\n",
       "355    TER               0.537068\n",
       "844   OMCL               0.536058"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sort_values('Historical Volatility', ascending=False) #highest Vol at the top\n",
    "\n",
    "# Determine the 90th percentile threshold (top 10% cutoff)\n",
    "vol_threshold = df['Historical Volatility'].quantile(0.90)\n",
    "\n",
    "# Drop tickers in the top decile\n",
    "df = df[df['Historical Volatility'] <= vol_threshold]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a637071-00cf-4f65-9800-ceb263f1bb78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>CNC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NVDA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>HBI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>TER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>844</th>\n",
       "      <td>OMCL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ticker\n",
       "147    CNC\n",
       "5     NVDA\n",
       "829    HBI\n",
       "355    TER\n",
       "844   OMCL"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp500_tickers = df # rename dataframe to sp500 tickers for the loops\n",
    "\n",
    "sp500_tickers.drop(columns=['Historical Volatility'],inplace=True)\n",
    "sp500_tickers.rename(columns={'Ticker' : 'ticker'},inplace=True)\n",
    "sp500_tickers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe60873",
   "metadata": {},
   "source": [
    "# Volatility Adjusted Returns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ce0240-d6f4-4a39-9aa8-b8e77a3dd45c",
   "metadata": {},
   "source": [
    "#### 1.) 1 Year Volatility-Adjusted Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "85bdcf95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a blank dataframe with the appropriate columns\n",
    "df = pd.DataFrame(columns=['Ticker', 'Vol Adjusted Return'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ccb67ed5-2e98-4d20-8b2d-4984a5ba1364",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  756 of 756 completed\n",
      "C:\\Users\\eabiz\\AppData\\Local\\Temp\\ipykernel_24852\\2641018204.py:20: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  ticker_data['Daily Return'] = ticker_data['Close'].pct_change()\n",
      "C:\\Users\\eabiz\\AppData\\Local\\Temp\\ipykernel_24852\\2641018204.py:20: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  ticker_data['Daily Return'] = ticker_data['Close'].pct_change()\n",
      "C:\\Users\\eabiz\\AppData\\Local\\Temp\\ipykernel_24852\\2641018204.py:20: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  ticker_data['Daily Return'] = ticker_data['Close'].pct_change()\n",
      "C:\\Users\\eabiz\\AppData\\Local\\Temp\\ipykernel_24852\\2641018204.py:20: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  ticker_data['Daily Return'] = ticker_data['Close'].pct_change()\n",
      "C:\\Users\\eabiz\\AppData\\Local\\Temp\\ipykernel_24852\\2641018204.py:20: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  ticker_data['Daily Return'] = ticker_data['Close'].pct_change()\n",
      "C:\\Users\\eabiz\\AppData\\Local\\Temp\\ipykernel_24852\\2641018204.py:20: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  ticker_data['Daily Return'] = ticker_data['Close'].pct_change()\n",
      "C:\\Users\\eabiz\\AppData\\Local\\Temp\\ipykernel_24852\\2641018204.py:20: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  ticker_data['Daily Return'] = ticker_data['Close'].pct_change()\n"
     ]
    }
   ],
   "source": [
    "# Collect rows in a list for concatenation\n",
    "rows_to_add = []\n",
    "\n",
    "# Convert tickers column to a list\n",
    "tickers = sp500_tickers['ticker'].tolist()\n",
    "\n",
    "# Batch download 2 years of data for all tickers at once\n",
    "data = yf.download(tickers, period='2y', group_by='ticker', threads=True, auto_adjust=False)\n",
    "\n",
    "for ticker in tickers:  # Iterate over the 'ticker' column in sp500_tickers dataframe\n",
    "    try:\n",
    "        # Retrieve individual ticker data from multi-ticker DataFrame\n",
    "        ticker_data = data[ticker].copy()\n",
    "\n",
    "        # Check if data is insufficient\n",
    "        if ticker_data.empty or len(ticker_data) < 252:  \n",
    "            raise ValueError(f\"Insufficient data for ticker: {ticker}\")\n",
    "\n",
    "        # Calculate daily returns\n",
    "        ticker_data['Daily Return'] = ticker_data['Close'].pct_change()\n",
    "\n",
    "        # Calculate percent return over a 1-year period (252 trading days)\n",
    "        ticker_data['Percent Return'] = ((ticker_data['Close'] - ticker_data['Close'].shift(252)) / ticker_data['Close'].shift(252)) * 100  \n",
    "\n",
    "        # Rolling window for std dev (daily returns)\n",
    "        window = 252  \n",
    "\n",
    "        # Calculate rolling standard deviation of daily returns\n",
    "        ticker_data['Rolling_Std'] = ticker_data['Daily Return'].rolling(window).std()\n",
    "\n",
    "        # Annualize rolling standard deviation to get historical annual volatility\n",
    "        ticker_data['Rolling_Hist_Vol'] = ticker_data['Rolling_Std'] * np.sqrt(window)\n",
    "\n",
    "        # Calculate volatility-adjusted returns\n",
    "        ticker_data['Vol_Adjusted_Return'] = ((ticker_data['Percent Return'])/100) / (ticker_data['Rolling_Hist_Vol'])\n",
    "\n",
    "        # Retrieve the last value of Vol Adjusted Return\n",
    "        vol_adjusted_return = ticker_data['Vol_Adjusted_Return'].iat[-1]\n",
    "\n",
    "        # Add the result to the list\n",
    "        rows_to_add.append({'Ticker': ticker, 'Vol Adjusted Return': vol_adjusted_return})\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving data for {ticker}: {str(e)}\")\n",
    "\n",
    "# Concatenate all rows into the DataFrame at once\n",
    "df = pd.concat([pd.DataFrame(rows_to_add)], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b5bf77c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values('Vol Adjusted Return', ascending=False)\n",
    "# Create a csv file with the results\n",
    "df.to_csv(\"Momentum Screen Results.csv\", index=False) # set index = to false, or else it'll create a column with index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0c92a3aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Vol Adjusted Return</th>\n",
       "      <th>Index1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TPR</td>\n",
       "      <td>4.290937</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NFLX</td>\n",
       "      <td>2.574694</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IBKR</td>\n",
       "      <td>2.557879</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JBL</td>\n",
       "      <td>2.541309</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CME</td>\n",
       "      <td>2.505368</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Ticker  Vol Adjusted Return  Index1\n",
       "0    TPR             4.290937       0\n",
       "1   NFLX             2.574694       1\n",
       "2   IBKR             2.557879       2\n",
       "3    JBL             2.541309       3\n",
       "4    CME             2.505368       4"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the csv file - momentum screen results\n",
    "df1 = pd.read_csv(\"Momentum Screen Results.csv\")\n",
    "\n",
    "df1['Index1'] = df1.index # create column of the index position\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba01814-9ee8-415e-a9a6-1cb0c8ffb178",
   "metadata": {},
   "source": [
    "### 2.) 6 Month Volatility Adjusted Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "84d8cc0f-ab42-4e8d-b912-9037cd58ec20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a blank dataframe with the appropriate columns\n",
    "df = pd.DataFrame(columns=['Ticker', 'Vol Adjusted Return'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "63f716d8-9aba-40c9-92de-27e8ddec1cac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  756 of 756 completed\n",
      "C:\\Users\\eabiz\\AppData\\Local\\Temp\\ipykernel_24852\\4286303003.py:20: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  ticker_data['Daily Return'] = ticker_data['Close'].pct_change()\n",
      "C:\\Users\\eabiz\\AppData\\Local\\Temp\\ipykernel_24852\\4286303003.py:20: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  ticker_data['Daily Return'] = ticker_data['Close'].pct_change()\n",
      "C:\\Users\\eabiz\\AppData\\Local\\Temp\\ipykernel_24852\\4286303003.py:20: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  ticker_data['Daily Return'] = ticker_data['Close'].pct_change()\n",
      "C:\\Users\\eabiz\\AppData\\Local\\Temp\\ipykernel_24852\\4286303003.py:20: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  ticker_data['Daily Return'] = ticker_data['Close'].pct_change()\n",
      "C:\\Users\\eabiz\\AppData\\Local\\Temp\\ipykernel_24852\\4286303003.py:20: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  ticker_data['Daily Return'] = ticker_data['Close'].pct_change()\n",
      "C:\\Users\\eabiz\\AppData\\Local\\Temp\\ipykernel_24852\\4286303003.py:20: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  ticker_data['Daily Return'] = ticker_data['Close'].pct_change()\n",
      "C:\\Users\\eabiz\\AppData\\Local\\Temp\\ipykernel_24852\\4286303003.py:20: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  ticker_data['Daily Return'] = ticker_data['Close'].pct_change()\n"
     ]
    }
   ],
   "source": [
    "# Collect rows in a list for concatenation\n",
    "rows_to_add = []\n",
    "\n",
    "# Convert tickers column to a list\n",
    "tickers = sp500_tickers['ticker'].tolist()\n",
    "\n",
    "# Batch download 1 year of data for all tickers at once\n",
    "data = yf.download(tickers, period='1y', group_by='ticker', threads=True, auto_adjust=False)\n",
    "\n",
    "for ticker in tickers:  # Iterate over the 'ticker' column in sp500_tickers dataframe\n",
    "    try:\n",
    "        # Retrieve individual ticker data from multi-ticker DataFrame\n",
    "        ticker_data = data[ticker].copy()\n",
    "        \n",
    "        # Check if data is insufficient\n",
    "        if ticker_data.empty or len(ticker_data) < 126:  \n",
    "            raise ValueError(f\"Insufficient data for ticker: {ticker}\")\n",
    "\n",
    "        # Calculate daily returns\n",
    "        ticker_data['Daily Return'] = ticker_data['Close'].pct_change()\n",
    "\n",
    "        # Calculate percent return over a 1-year period (252 trading days)\n",
    "        ticker_data['Percent Return'] = ((ticker_data['Close'] - ticker_data['Close'].shift(126)) / ticker_data['Close'].shift(126)) * 100  \n",
    "\n",
    "        # Rolling window for std dev (daily returns)\n",
    "        window = 126  \n",
    "\n",
    "        # Calculate rolling standard deviation of daily returns\n",
    "        ticker_data['Rolling_Std'] = ticker_data['Daily Return'].rolling(window).std()\n",
    "\n",
    "        # Annualize rolling standard deviation to get historical annual volatility\n",
    "        ticker_data['Rolling_Hist_Vol'] = ticker_data['Rolling_Std'] * np.sqrt(252)\n",
    "\n",
    "        # Calculate volatility-adjusted returns\n",
    "        ticker_data['Vol_Adjusted_Return'] = ((ticker_data['Percent Return'])/100) / (ticker_data['Rolling_Hist_Vol'])\n",
    "\n",
    "        # Retrieve the last value of Vol Adjusted Return\n",
    "        vol_adjusted_return = ticker_data['Vol_Adjusted_Return'].iat[-1]\n",
    "\n",
    "        # Add the result to the list\n",
    "        rows_to_add.append({'Ticker': ticker, 'Vol Adjusted Return': vol_adjusted_return})\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving data for {ticker}: {str(e)}\")\n",
    "\n",
    "# Concatenate all rows into the DataFrame at once\n",
    "df = pd.concat([pd.DataFrame(rows_to_add)], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "43123288-e83c-47c5-bdb3-ed0fee32d129",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values('Vol Adjusted Return', ascending=False)\n",
    "# Create a csv file with the results\n",
    "df.to_csv(\"6 Month Momentum Screen Results.csv\", index=False) # set index = to false, or else it'll create a column with index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d06a2740-c9da-46b5-8a7f-f852b1e4820b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Vol Adjusted Return</th>\n",
       "      <th>Index2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NEU</td>\n",
       "      <td>1.822781</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SXT</td>\n",
       "      <td>1.588431</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ORA</td>\n",
       "      <td>1.474258</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>APH</td>\n",
       "      <td>1.452337</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CW</td>\n",
       "      <td>1.430534</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Ticker  Vol Adjusted Return  Index2\n",
       "0    NEU             1.822781       0\n",
       "1    SXT             1.588431       1\n",
       "2    ORA             1.474258       2\n",
       "3    APH             1.452337       3\n",
       "4     CW             1.430534       4"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv(\"6 Month Momentum Screen Results.csv\")\n",
    "df2['Index2'] = df2.index # create column of the index position\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46124942-4a4b-4c6a-90f3-80af3c534a0f",
   "metadata": {},
   "source": [
    "### Merge Both Dataframes - 1yr and 6M vol volatility adjusted returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e1775301-68e1-41f8-ade1-884e7548eafd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Vol Adjusted Return_x</th>\n",
       "      <th>Index1</th>\n",
       "      <th>Vol Adjusted Return_y</th>\n",
       "      <th>Index2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TPR</td>\n",
       "      <td>4.290937</td>\n",
       "      <td>0</td>\n",
       "      <td>1.084791</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NFLX</td>\n",
       "      <td>2.574694</td>\n",
       "      <td>1</td>\n",
       "      <td>0.526624</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IBKR</td>\n",
       "      <td>2.557879</td>\n",
       "      <td>2</td>\n",
       "      <td>0.257938</td>\n",
       "      <td>208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JBL</td>\n",
       "      <td>2.541309</td>\n",
       "      <td>3</td>\n",
       "      <td>0.864114</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CME</td>\n",
       "      <td>2.505368</td>\n",
       "      <td>4</td>\n",
       "      <td>0.943848</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Ticker  Vol Adjusted Return_x  Index1  Vol Adjusted Return_y  Index2\n",
       "0    TPR               4.290937       0               1.084791      15\n",
       "1   NFLX               2.574694       1               0.526624     107\n",
       "2   IBKR               2.557879       2               0.257938     208\n",
       "3    JBL               2.541309       3               0.864114      42\n",
       "4    CME               2.505368       4               0.943848      28"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform an inner join to include only matching tickers\n",
    "df = pd.merge(df1, df2, on='Ticker', how='inner')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f7fb03-a244-4d26-a0b5-539446e632a2",
   "metadata": {},
   "source": [
    "### Calculate Average Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0e140a4d-2190-44c6-961f-cb0db8f56be3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Vol Adjusted Return_x</th>\n",
       "      <th>Index1</th>\n",
       "      <th>Vol Adjusted Return_y</th>\n",
       "      <th>Index2</th>\n",
       "      <th>average_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TPR</td>\n",
       "      <td>4.290937</td>\n",
       "      <td>0</td>\n",
       "      <td>1.084791</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NFLX</td>\n",
       "      <td>2.574694</td>\n",
       "      <td>1</td>\n",
       "      <td>0.526624</td>\n",
       "      <td>107</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IBKR</td>\n",
       "      <td>2.557879</td>\n",
       "      <td>2</td>\n",
       "      <td>0.257938</td>\n",
       "      <td>208</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JBL</td>\n",
       "      <td>2.541309</td>\n",
       "      <td>3</td>\n",
       "      <td>0.864114</td>\n",
       "      <td>42</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CME</td>\n",
       "      <td>2.505368</td>\n",
       "      <td>4</td>\n",
       "      <td>0.943848</td>\n",
       "      <td>28</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Ticker  Vol Adjusted Return_x  Index1  Vol Adjusted Return_y  Index2  \\\n",
       "0    TPR               4.290937       0               1.084791      15   \n",
       "1   NFLX               2.574694       1               0.526624     107   \n",
       "2   IBKR               2.557879       2               0.257938     208   \n",
       "3    JBL               2.541309       3               0.864114      42   \n",
       "4    CME               2.505368       4               0.943848      28   \n",
       "\n",
       "   average_rank  \n",
       "0            15  \n",
       "1           108  \n",
       "2           210  \n",
       "3            45  \n",
       "4            32  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate average rank\n",
    "\n",
    "df['average_rank'] = df['Index1'] + df['Index2'] # simply add the two ranks\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4e90e1de-42e4-489c-9479-d4f17c49be88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Vol Adjusted Return_x</th>\n",
       "      <th>Index1</th>\n",
       "      <th>Vol Adjusted Return_y</th>\n",
       "      <th>Index2</th>\n",
       "      <th>average_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TPR</td>\n",
       "      <td>4.290937</td>\n",
       "      <td>0</td>\n",
       "      <td>1.084791</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CAH</td>\n",
       "      <td>2.454252</td>\n",
       "      <td>6</td>\n",
       "      <td>1.253052</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CW</td>\n",
       "      <td>2.207637</td>\n",
       "      <td>11</td>\n",
       "      <td>1.430534</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>APH</td>\n",
       "      <td>2.025876</td>\n",
       "      <td>15</td>\n",
       "      <td>1.452337</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>FHI</td>\n",
       "      <td>2.277703</td>\n",
       "      <td>10</td>\n",
       "      <td>1.168690</td>\n",
       "      <td>11</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ticker  Vol Adjusted Return_x  Index1  Vol Adjusted Return_y  Index2  \\\n",
       "0     TPR               4.290937       0               1.084791      15   \n",
       "6     CAH               2.454252       6               1.253052       9   \n",
       "11     CW               2.207637      11               1.430534       4   \n",
       "15    APH               2.025876      15               1.452337       3   \n",
       "10    FHI               2.277703      10               1.168690      11   \n",
       "\n",
       "    average_rank  \n",
       "0             15  \n",
       "6             15  \n",
       "11            15  \n",
       "15            18  \n",
       "10            21  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sort_values('average_rank', ascending=True)\n",
    "# Create a csv file with the results\n",
    "df.to_csv(\"Momentum Screen Results.csv\", index=False) # set index = to false, or else it'll create a column with index\n",
    "df.head()\n",
    "\n",
    "\n",
    "###############"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477c1f59",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Convexity of Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "145390f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#only keep first 100 rows of the Momentum Screen Results \n",
    "df1 = df1.iloc[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2d0e9d66",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error retrieving data for FOX: 'Adj Close'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error retrieving data for FOXA: 'Adj Close'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error retrieving data for WELL: 'Adj Close'\n",
      "Error retrieving data for NI: 'Adj Close'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error retrieving data for T: 'Adj Close'\n",
      "Error retrieving data for SFM: 'Adj Close'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error retrieving data for PM: 'Adj Close'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error retrieving data for NFG: 'Adj Close'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error retrieving data for VTR: 'Adj Close'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error retrieving data for TMUS: 'Adj Close'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error retrieving data for KMI: 'Adj Close'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error retrieving data for DTM: 'Adj Close'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error retrieving data for BK: 'Adj Close'\n",
      "Error retrieving data for WMB: 'Adj Close'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error retrieving data for ETR: 'Adj Close'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error retrieving data for HWM: 'Adj Close'\n",
      "Error retrieving data for BSX: 'Adj Close'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error retrieving data for UNM: 'Adj Close'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error retrieving data for K: 'Adj Close'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error retrieving data for RTX: 'Adj Close'\n",
      "Error retrieving data for AEE: 'Adj Close'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error retrieving data for MMM: 'Adj Close'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error retrieving data for MO: 'Adj Close'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error retrieving data for EVRG: 'Adj Close'\n",
      "Error retrieving data for EXLS: 'Adj Close'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error retrieving data for BRO: 'Adj Close'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error retrieving data for OGE: 'Adj Close'\n",
      "Error retrieving data for FI: 'Adj Close'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error retrieving data for ACIW: 'Adj Close'\n",
      "Error retrieving data for ORI: 'Adj Close'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error retrieving data for XEL: 'Adj Close'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error retrieving data for WEC: 'Adj Close'\n",
      "Error retrieving data for PNW: 'Adj Close'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error retrieving data for ATO: 'Adj Close'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error retrieving data for CNO: 'Adj Close'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error retrieving data for PPL: 'Adj Close'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error retrieving data for GILD: 'Adj Close'\n",
      "Error retrieving data for WMT: 'Adj Close'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error retrieving data for LNT: 'Adj Close'\n",
      "Error retrieving data for IBKR: 'Adj Close'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error retrieving data for CMS: 'Adj Close'\n",
      "Error retrieving data for G: 'Adj Close'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error retrieving data for SO: 'Adj Close'\n",
      "Error retrieving data for NFLX: 'Adj Close'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error retrieving data for IDA: 'Adj Close'\n",
      "Error retrieving data for ICE: 'Adj Close'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error retrieving data for DUK: 'Adj Close'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error retrieving data for GLW: 'Adj Close'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error retrieving data for AEP: 'Adj Close'\n",
      "Error retrieving data for EPR: 'Adj Close'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error retrieving data for IRT: 'Adj Close'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error retrieving data for RCL: 'Adj Close'\n",
      "Error retrieving data for EXEL: 'Adj Close'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error retrieving data for FICO: 'Adj Close'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error retrieving data for SR: 'Adj Close'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error retrieving data for RSG: 'Adj Close'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error retrieving data for CME: 'Adj Close'\n",
      "Error retrieving data for ALE: 'Adj Close'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error retrieving data for SRCL: 'Adj Close'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error retrieving data for COKE: 'Adj Close'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error retrieving data for PGR: 'Adj Close'\n",
      "Error retrieving data for TTWO: 'Adj Close'\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[92], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m Ticker \u001b[38;5;129;01min\u001b[39;00m df1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTicker\u001b[39m\u001b[38;5;124m'\u001b[39m]:  \u001b[38;5;66;03m# Iterate over the 'Ticker' column\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m      9\u001b[0m         \u001b[38;5;66;03m# Download 2 years of historical data\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m         data \u001b[38;5;241m=\u001b[39m yf\u001b[38;5;241m.\u001b[39mdownload(Ticker, period\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2y\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     12\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m data\u001b[38;5;241m.\u001b[39mempty \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m252\u001b[39m:  \u001b[38;5;66;03m# Check if data is insufficient\u001b[39;00m\n\u001b[0;32m     13\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInsufficient data for ticker: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mTicker\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\yfinance\\utils.py:104\u001b[0m, in \u001b[0;36mlog_indent_decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    101\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEntering \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m()\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m IndentationContext():\n\u001b[1;32m--> 104\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    106\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExiting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m()\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\yfinance\\multi.py:162\u001b[0m, in \u001b[0;36mdownload\u001b[1;34m(tickers, start, end, actions, threads, ignore_tz, group_by, auto_adjust, back_adjust, repair, keepna, progress, period, interval, prepost, proxy, rounding, timeout, session, multi_level_index)\u001b[0m\n\u001b[0;32m    155\u001b[0m         _download_one_threaded(ticker, period\u001b[38;5;241m=\u001b[39mperiod, interval\u001b[38;5;241m=\u001b[39minterval,\n\u001b[0;32m    156\u001b[0m                                start\u001b[38;5;241m=\u001b[39mstart, end\u001b[38;5;241m=\u001b[39mend, prepost\u001b[38;5;241m=\u001b[39mprepost,\n\u001b[0;32m    157\u001b[0m                                actions\u001b[38;5;241m=\u001b[39mactions, auto_adjust\u001b[38;5;241m=\u001b[39mauto_adjust,\n\u001b[0;32m    158\u001b[0m                                back_adjust\u001b[38;5;241m=\u001b[39mback_adjust, repair\u001b[38;5;241m=\u001b[39mrepair, keepna\u001b[38;5;241m=\u001b[39mkeepna,\n\u001b[0;32m    159\u001b[0m                                progress\u001b[38;5;241m=\u001b[39m(progress \u001b[38;5;129;01mand\u001b[39;00m i \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m), proxy\u001b[38;5;241m=\u001b[39mproxy,\n\u001b[0;32m    160\u001b[0m                                rounding\u001b[38;5;241m=\u001b[39mrounding, timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(shared\u001b[38;5;241m.\u001b[39m_DFS) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(tickers):\n\u001b[1;32m--> 162\u001b[0m         _time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[0;32m    163\u001b[0m \u001b[38;5;66;03m# download synchronously\u001b[39;00m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, ticker \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tickers):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Collect rows in a list for concatenation\n",
    "rows_to_add_4 = []\n",
    "\n",
    "# Initialize a results DataFrame\n",
    "results_df = pd.DataFrame(columns=['Ticker', 'Convexity Ratio'])\n",
    "\n",
    "for Ticker in df1['Ticker']:  # Iterate over the 'Ticker' column\n",
    "    try:\n",
    "        # Download 2 years of historical data\n",
    "        data = yf.download(Ticker, period='2y')\n",
    "        \n",
    "        if data.empty or len(data) < 252:  # Check if data is insufficient\n",
    "            raise ValueError(f\"Insufficient data for ticker: {Ticker}\")\n",
    "        \n",
    "        # Create a DataFrame for returns\n",
    "        df = pd.DataFrame()\n",
    "        df['Return'] = data['Adj Close'].pct_change()\n",
    "\n",
    "        # Calculate the slope using a rolling window\n",
    "        window = 50  # Adjust window size as needed\n",
    "        df['Slope'] = df['Return'].rolling(window).apply(\n",
    "            lambda x: np.polyfit(np.arange(len(x)), x, 1)[0], raw=True\n",
    "        )\n",
    "\n",
    "        # Compute the second derivative of the slope\n",
    "        df['Second_Derivative'] = df['Slope'].diff()\n",
    "\n",
    "        # Calculate the convexity ratio\n",
    "        df['Convexity_Ratio'] = df['Second_Derivative'] / df['Slope']\n",
    "        \n",
    "        # Extract the most recent convexity ratio\n",
    "        convexity_ratio = df['Convexity_Ratio'].iloc[-1]\n",
    "        \n",
    "        # Add the result to the list\n",
    "        rows_to_add_4.append({'Ticker': Ticker, 'Convexity Ratio': convexity_ratio})\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving data for {Ticker}: {str(e)}\")\n",
    "        \n",
    "# Concatenate all rows into the DataFrame at once\n",
    "results_df = pd.concat([pd.DataFrame(rows_to_add_4)], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6f912e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = results_df.sort_values(by='Convexity Ratio', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "bc140635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Convexity Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>MRK</td>\n",
       "      <td>7.440757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>INTC</td>\n",
       "      <td>3.696518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>PEP</td>\n",
       "      <td>2.642901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>TXN</td>\n",
       "      <td>1.623321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>XOM</td>\n",
       "      <td>1.375793</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ticker  Convexity Ratio\n",
       "46    MRK         7.440757\n",
       "48   INTC         3.696518\n",
       "44    PEP         2.642901\n",
       "24    TXN         1.623321\n",
       "20    XOM         1.375793"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a3dc2896",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a new csv file with our FIP results\n",
    "df2.to_csv('Convexity_Results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987ca273",
   "metadata": {},
   "source": [
    "# Convexity Based on Quadratic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4bc4d280",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.iloc[:400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "526bb229-9c5f-44e3-91e0-58008e4595d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  14 of 14 completed\n"
     ]
    }
   ],
   "source": [
    "rows_to_add_2 = []\n",
    "\n",
    "# Initialize an empty DataFrame to store results\n",
    "df_convexity = pd.DataFrame(columns=['Ticker', 'Convexity Score'])\n",
    "\n",
    "# Get tickers from df['Ticker'] list\n",
    "tickers = df['Ticker'].tolist()\n",
    "\n",
    "# Batch download 2 years of data for all tickers at once\n",
    "data = yf.download(tickers, period='2y', group_by='ticker', threads=True, auto_adjust=False)\n",
    "\n",
    "for ticker in tickers:\n",
    "    try:\n",
    "        # Retrieve individual ticker data from multi-ticker DataFrame\n",
    "        ticker_data = data[ticker].copy()\n",
    "\n",
    "        # Keep only last 252 rows... 252 trading days\n",
    "        ticker_data = ticker_data.tail(252)\n",
    "\n",
    "        # Ensure there is sufficient data\n",
    "        if ticker_data.empty or len(ticker_data) < 252:  \n",
    "            raise ValueError(f\"Insufficient data for ticker: {ticker}\")\n",
    "        \n",
    "        # Calculate daily returns (percentage change)\n",
    "        ticker_data['Return'] = ticker_data['Close'].pct_change() * 100\n",
    "\n",
    "        # Drop the first row since the return for the first day is NaN\n",
    "        ticker_data.dropna(inplace=True)\n",
    "        \n",
    "        # Create an ordinal time variable (index of the data)\n",
    "        ticker_data.loc[:, 'Time'] = np.arange(len(ticker_data))\n",
    "        \n",
    "        # Prepare the independent variables (Time and Time^2 for quadratic regression)\n",
    "        X = np.vstack([ticker_data['Time'], ticker_data['Time']**2]).T\n",
    "        y = ticker_data['Return'].values\n",
    "        \n",
    "        # Perform a quadratic regression\n",
    "        model = LinearRegression().fit(X, y)\n",
    "        \n",
    "        # The convexity is the coefficient of the squared time term\n",
    "        convexity = model.coef_[1]  # This is the coefficient of Time^2 (quadratic term)\n",
    "        \n",
    "        # Add the result to the list\n",
    "        rows_to_add_2.append({'Ticker': ticker, 'Convexity Score': convexity})\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving data for {ticker}: {str(e)}\")\n",
    "\n",
    "# Concatenate all rows into the DataFrame at once\n",
    "df_convexity = pd.concat([pd.DataFrame(rows_to_add_2)], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ee3501da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_convexity = df_convexity.sort_values('Convexity Score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a046b594",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_convexity.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "afa294b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Convexity Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OKE</td>\n",
       "      <td>0.000020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NI</td>\n",
       "      <td>0.000013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TATT</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TPR</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CLBT</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Ticker  Convexity Score\n",
       "0    OKE         0.000020\n",
       "1     NI         0.000013\n",
       "2   TATT         0.000007\n",
       "3    TPR         0.000007\n",
       "4   CLBT         0.000006"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_convexity.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "79469461",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_convexity.to_csv(\"Convexity_Score_Quadratic_Method.csv\")\n",
    "\n",
    "\n",
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b20760",
   "metadata": {},
   "source": [
    "# Momentum Quality - FIP (Frog in the Pan Score)\n",
    "\n",
    "ID or FIP Score\n",
    "ID = sign x [% Negative - % Positive]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "71088c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keep first 400 rows of the Momentum Screen Results\n",
    "df = df.iloc[:400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6a2dcab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a blank dataframe with the appropriate columns\n",
    "df_FIP = pd.DataFrame(columns=['Ticker', 'FIP_Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7f286388-ab39-4f3e-bc84-23d6ca56c298",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  397 of 397 completed\n"
     ]
    }
   ],
   "source": [
    "rows_to_add_3 = []\n",
    "\n",
    "# Get list of tickers from df\n",
    "tickers = df['Ticker'].tolist()\n",
    "\n",
    "# Batch download 2 years of data for all tickers at once\n",
    "data = yf.download(tickers, period='2y', group_by='ticker', threads=True, auto_adjust=False)\n",
    "\n",
    "for Ticker in tickers:  # Iterate over the 'ticker' column in df\n",
    "    try:\n",
    "        # Retrieve individual ticker data from multi-ticker DataFrame\n",
    "        ticker_data = data[Ticker].copy()\n",
    "        ticker_data = ticker_data.tail(252)  # Use only last 252 rows... for 252 trading days\n",
    "\n",
    "        if ticker_data.empty or len(ticker_data) < 252:  # Check if data is insufficient\n",
    "            raise ValueError(f\"Insufficient data for ticker: {Ticker}\")\n",
    "        \n",
    "        ticker_data['Percent Return'] = (ticker_data['Close'].pct_change()) * 100\n",
    "\n",
    "        if ticker_data['Percent Return'].cumsum().iat[-1] > 0:\n",
    "            sign = 1\n",
    "        elif ticker_data['Percent Return'].cumsum().iat[-1] < 0:\n",
    "            sign = -1\n",
    "        else:\n",
    "            sign = 0\n",
    "\n",
    "        positive_days = (ticker_data['Percent Return'] > 0).sum()\n",
    "        negative_days = (ticker_data['Percent Return'] < 0).sum()\n",
    "        flat_days = (ticker_data['Percent Return'] == 0).sum()\n",
    "        pct_positive = round(positive_days / len(ticker_data), 4)\n",
    "        pct_negative = round(negative_days / len(ticker_data), 4)\n",
    "        FIP_Score = round(sign * (pct_negative - pct_positive), 4)\n",
    "\n",
    "        # Add the result to the list\n",
    "        rows_to_add_3.append({'Ticker': Ticker, 'FIP Score': FIP_Score})\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving data for {Ticker}: {str(e)}\")\n",
    "\n",
    "df_FIP = pd.concat([pd.DataFrame(rows_to_add_3)], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3a7352bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_FIP = df_FIP.sort_values('FIP Score', ascending=True) # ascending = True since the best scores are negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fc681a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_FIP.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5a2bc2ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>FIP Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DTE</td>\n",
       "      <td>-0.2381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CW</td>\n",
       "      <td>-0.2301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NDAQ</td>\n",
       "      <td>-0.2222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GL</td>\n",
       "      <td>-0.2103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ANET</td>\n",
       "      <td>-0.2024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Ticker  FIP Score\n",
       "0    DTE    -0.2381\n",
       "1     CW    -0.2301\n",
       "2   NDAQ    -0.2222\n",
       "3     GL    -0.2103\n",
       "4   ANET    -0.2024"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_FIP.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "aa493619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new csv file with our FIP results\n",
    "df_FIP.to_csv('Momentum_FIP_Results.csv', index=False)\n",
    "\n",
    "\n",
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ce12bc",
   "metadata": {},
   "source": [
    "# Combine Dataframes and Rank Tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9f6a30e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create column of index #\n",
    "df['index_vol_rank'] = df.index #vol adjusted returns df\n",
    "\n",
    "#Create column of index #\n",
    "df_FIP['index_fip_rank'] = df_FIP.index # FIP df\n",
    "\n",
    "# create column of index # \n",
    "#df_convexity['Index3'] = df_convexity.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "079f383a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform an inner join to include only matching tickers\n",
    "merged = pd.merge(df_FIP, df, on='Ticker', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c62a1d17-c25c-4648-97bd-7370000da08a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>FIP Score</th>\n",
       "      <th>index_fip_rank</th>\n",
       "      <th>Vol Adjusted Return_x</th>\n",
       "      <th>Index1</th>\n",
       "      <th>Vol Adjusted Return_y</th>\n",
       "      <th>Index2</th>\n",
       "      <th>average_rank</th>\n",
       "      <th>index_vol_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DTE</td>\n",
       "      <td>-0.2381</td>\n",
       "      <td>0</td>\n",
       "      <td>0.725385</td>\n",
       "      <td>170</td>\n",
       "      <td>0.804589</td>\n",
       "      <td>51</td>\n",
       "      <td>221</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CW</td>\n",
       "      <td>-0.2301</td>\n",
       "      <td>1</td>\n",
       "      <td>2.207637</td>\n",
       "      <td>11</td>\n",
       "      <td>1.430534</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NDAQ</td>\n",
       "      <td>-0.2222</td>\n",
       "      <td>2</td>\n",
       "      <td>1.795989</td>\n",
       "      <td>29</td>\n",
       "      <td>0.588955</td>\n",
       "      <td>96</td>\n",
       "      <td>125</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GL</td>\n",
       "      <td>-0.2103</td>\n",
       "      <td>3</td>\n",
       "      <td>1.851685</td>\n",
       "      <td>24</td>\n",
       "      <td>0.466128</td>\n",
       "      <td>123</td>\n",
       "      <td>147</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ANET</td>\n",
       "      <td>-0.2024</td>\n",
       "      <td>4</td>\n",
       "      <td>0.718298</td>\n",
       "      <td>172</td>\n",
       "      <td>0.090313</td>\n",
       "      <td>291</td>\n",
       "      <td>463</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Ticker  FIP Score  index_fip_rank  Vol Adjusted Return_x  Index1  \\\n",
       "0    DTE    -0.2381               0               0.725385     170   \n",
       "1     CW    -0.2301               1               2.207637      11   \n",
       "2   NDAQ    -0.2222               2               1.795989      29   \n",
       "3     GL    -0.2103               3               1.851685      24   \n",
       "4   ANET    -0.2024               4               0.718298     172   \n",
       "\n",
       "   Vol Adjusted Return_y  Index2  average_rank  index_vol_rank  \n",
       "0               0.804589      51           221             170  \n",
       "1               1.430534       4            15              11  \n",
       "2               0.588955      96           125              29  \n",
       "3               0.466128     123           147              24  \n",
       "4               0.090313     291           463             172  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84790d2f",
   "metadata": {},
   "source": [
    "### Next cell is only necessary if adding a third filter to the ranking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "aa2f61cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the result with the third DataFrame\n",
    "merged = pd.merge(merged, df_convexity, on='Ticker', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "9453cb8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>FIP Score</th>\n",
       "      <th>index_fip_rank</th>\n",
       "      <th>Vol Adjusted Return_x</th>\n",
       "      <th>Index1</th>\n",
       "      <th>Vol Adjusted Return_y</th>\n",
       "      <th>Index2</th>\n",
       "      <th>average_rank</th>\n",
       "      <th>index_vol_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DTE</td>\n",
       "      <td>-0.2381</td>\n",
       "      <td>0</td>\n",
       "      <td>0.815923</td>\n",
       "      <td>140</td>\n",
       "      <td>0.844911</td>\n",
       "      <td>35</td>\n",
       "      <td>175</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CW</td>\n",
       "      <td>-0.2143</td>\n",
       "      <td>1</td>\n",
       "      <td>2.174156</td>\n",
       "      <td>12</td>\n",
       "      <td>1.298241</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NDAQ</td>\n",
       "      <td>-0.2143</td>\n",
       "      <td>2</td>\n",
       "      <td>1.609173</td>\n",
       "      <td>43</td>\n",
       "      <td>0.555771</td>\n",
       "      <td>89</td>\n",
       "      <td>132</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GL</td>\n",
       "      <td>-0.2024</td>\n",
       "      <td>3</td>\n",
       "      <td>1.630861</td>\n",
       "      <td>42</td>\n",
       "      <td>0.382556</td>\n",
       "      <td>132</td>\n",
       "      <td>174</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CME</td>\n",
       "      <td>-0.2024</td>\n",
       "      <td>4</td>\n",
       "      <td>2.321029</td>\n",
       "      <td>7</td>\n",
       "      <td>0.953891</td>\n",
       "      <td>24</td>\n",
       "      <td>31</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Ticker  FIP Score  index_fip_rank  Vol Adjusted Return_x  Index1  \\\n",
       "0    DTE    -0.2381               0               0.815923     140   \n",
       "1     CW    -0.2143               1               2.174156      12   \n",
       "2   NDAQ    -0.2143               2               1.609173      43   \n",
       "3     GL    -0.2024               3               1.630861      42   \n",
       "4    CME    -0.2024               4               2.321029       7   \n",
       "\n",
       "   Vol Adjusted Return_y  Index2  average_rank  index_vol_rank  \n",
       "0               0.844911      35           175             140  \n",
       "1               1.298241       4            16              12  \n",
       "2               0.555771      89           132              43  \n",
       "3               0.382556     132           174              42  \n",
       "4               0.953891      24            31               7  "
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bcd615b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the score (sum of indices)\n",
    "\n",
    "#merged['Score'] = merged['index_vol_rank'] + merged['index_fip_rank'] + merged['Index3']\n",
    "merged['Score'] = merged['index_vol_rank'] + merged['index_fip_rank']\n",
    "\n",
    "# Sort the result by the score\n",
    "sorted_df = merged.sort_values('Score', ascending=True)\n",
    "# Select relevant columns for the output\n",
    "result = sorted_df[['Ticker', 'Score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "aa269535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CME</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>IBKR</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CW</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CAH</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>BK</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ticker  Score\n",
       "5     CME      9\n",
       "7    IBKR      9\n",
       "1      CW     12\n",
       "9     CAH     15\n",
       "11     BK     19"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "70045d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv(\"Momentum_Ranked.csv\",index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#####"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d9c846-cbc3-46ad-a653-9238b1b2d1d0",
   "metadata": {},
   "source": [
    "# Volatility Targetting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c1afa1-41f7-4286-8737-3f9cba5f1d27",
   "metadata": {},
   "source": [
    "This methodology transforms a set of screened tickers into a riskcontrolled portfolio. By estimating each assets historical volatility and using inversevolatility weighting, the process allocates more capital to steadier names while reducing exposure to highly volatile ones. The final scaling step ensures that the entire portfolio is expected to experience a predefined annualised volatility (e.g. 20%), giving you a consistent risk profile regardless of market regime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6ed80d48-080d-4a8b-b5d8-d1554731a7e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CME</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>IBKR</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CW</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CAH</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>BK</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ticker  Score\n",
       "5     CME      9\n",
       "7    IBKR      9\n",
       "1      CW     12\n",
       "9     CAH     15\n",
       "11     BK     19"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keep only the top 50 equities\n",
    "result = result.head(50)\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54a5f46-6dda-4db8-99bd-752de2d9cdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a blank DataFrame to store the results\n",
    "df_voltarget = pd.DataFrame(columns=['Ticker', 'Volatility', 'Weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "28e04396-5f6c-4775-95e0-c908a25d183e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  50 of 50 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Ticker  Volatility    Weight\n",
      "0     CME    0.182024  3.626438\n",
      "1    IBKR    0.438988  1.503681\n",
      "2      CW    0.331014  1.994171\n",
      "3     CAH    0.219776  3.003507\n",
      "4      BK    0.239761  2.753145\n",
      "5     HWM    0.362171  1.822616\n",
      "6      GL    0.276899  2.383894\n",
      "7    NDAQ    0.233880  2.822376\n",
      "8    WELL    0.222554  2.966014\n",
      "9     LYV    0.294843  2.238813\n",
      "10   FFIV    0.291109  2.267531\n",
      "11     NI    0.192702  3.425485\n",
      "12   GILD    0.265374  2.487426\n",
      "13      T    0.229553  2.875583\n",
      "14    WMT    0.239691  2.753953\n",
      "15    WWD    0.308244  2.141481\n",
      "16     GE    0.326135  2.024002\n",
      "17    FHI    0.222335  2.968932\n",
      "18   TTWO    0.303504  2.174925\n",
      "19    EME    0.413555  1.596155\n",
      "20   ORCL    0.439194  1.502975\n",
      "21     PM    0.271114  2.434766\n",
      "22    APH    0.355601  1.856289\n",
      "23   CSCO    0.231276  2.854158\n",
      "24    ETR    0.268616  2.457405\n",
      "25   VRSN    0.251921  2.620258\n",
      "26   TRMB    0.339725  1.943036\n",
      "27   NFLX    0.331140  1.993414\n",
      "28    BSX    0.225388  2.928717\n",
      "29    CNP    0.188522  3.501430\n",
      "30   EVRG    0.166999  3.952713\n",
      "31   SCHW    0.264430  2.496305\n",
      "32    JPM    0.278310  2.371810\n",
      "33    UGI    0.269523  2.449137\n",
      "34    RJF    0.287458  2.296326\n",
      "35    JBL    0.384400  1.717218\n",
      "36    TPR    0.422670  1.561733\n",
      "37    SFM    0.364527  1.810834\n",
      "38   FTNT    0.433171  1.523873\n",
      "39    NFG    0.213139  3.097038\n",
      "40    GLW    0.326876  2.019417\n",
      "41      V    0.227650  2.899619\n",
      "42    ATO    0.169754  3.888550\n",
      "43   BKNG    0.275857  2.392899\n",
      "44    STT    0.279489  2.361806\n",
      "45    RTX    0.257340  2.565079\n",
      "46    ICE    0.184273  3.582165\n",
      "47   TMUS    0.277714  2.376898\n",
      "48     MA    0.221500  2.980128\n",
      "49    IBM    0.290558  2.271833\n"
     ]
    }
   ],
   "source": [
    "# Collect rows in a list for concatenation\n",
    "rows_to_add = []\n",
    "\n",
    "# Extract tickers from the df\n",
    "tickers = result['Ticker'].dropna().tolist()\n",
    "\n",
    "# Batch download price data for all tickers at once (2 years)\n",
    "# This gives enough history to compute a 1-year (252 trading day) volatility estimate\n",
    "data = yf.download(tickers, period='2y', group_by='ticker', threads=True, auto_adjust=False)\n",
    "\n",
    "# Prepare a DataFrame to store daily returns\n",
    "returns_df = pd.DataFrame()\n",
    "\n",
    "# Loop through each ticker\n",
    "for ticker in tickers:\n",
    "    try:\n",
    "        # Retrieve individual ticker data from the multiticker DataFrame\n",
    "        ticker_data = data[ticker].copy()\n",
    "        ticker_data = ticker_data.tail(252)  # use the last 252 trading days (~1 year)\n",
    "\n",
    "        # Verify sufficient data\n",
    "        if ticker_data.empty or len(ticker_data) < 252:\n",
    "            raise ValueError(f\"Insufficient data for ticker: {ticker}\")\n",
    "\n",
    "        # Calculate daily returns\n",
    "        ticker_data['Daily Return'] = ticker_data['Close'].pct_change()\n",
    "\n",
    "        # Add the daily returns to the returns matrix (drop the first NaN)\n",
    "        returns_df[ticker] = ticker_data['Daily Return'].dropna()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving data for {ticker}: {str(e)}\")\n",
    "\n",
    "# Drop any rows with missing values to align the date\n",
    "returns_df = returns_df.dropna()\n",
    "\n",
    "# Annualised vol for each ticker\n",
    "volatility = returns_df.std() * np.sqrt(252)\n",
    "\n",
    "# Compute inversevolatility weights (raw weights before scaling)\n",
    "inverse_vol = 1 / volatility\n",
    "raw_weights = inverse_vol / inverse_vol.sum()\n",
    "\n",
    "# Compute the covariance matrix (annualised) for the returns\n",
    "cov_matrix = returns_df.cov() * 252\n",
    "\n",
    "# Calculate the current portfolio volatility using the raw weights\n",
    "current_vol = np.sqrt(raw_weights.T @ cov_matrix @ raw_weights)\n",
    "\n",
    "target_vol = 0.20\n",
    "\n",
    "# Determine scaling factor needed to hit the target volatility\n",
    "scaling_factor = target_vol / current_vol\n",
    "\n",
    "# Final weights after scaling\n",
    "final_weights = (raw_weights * scaling_factor)*100\n",
    "\n",
    "# Build the result rows\n",
    "for ticker in final_weights.index:\n",
    "    rows_to_add.append({\n",
    "        'Ticker': ticker,\n",
    "        'Volatility': volatility[ticker],\n",
    "        'Weight': final_weights[ticker]\n",
    "    })\n",
    "\n",
    "# Concatenate into the final DataFrame\n",
    "df_voltarget = pd.concat([pd.DataFrame(rows_to_add)], ignore_index=True)\n",
    "\n",
    "print(df_voltarget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "58843b8f-c7b3-4854-8efd-42a1119364bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Portfolio Exposure:\n",
      "124.53795715570631\n",
      "\n",
      "Average % Exposure:\n",
      "2.490759143114126\n"
     ]
    }
   ],
   "source": [
    "print('Total Portfolio Exposure:')\n",
    "print(df_voltarget['Weight'].sum())\n",
    "print()\n",
    "print('Average % Exposure:')\n",
    "print(df_voltarget['Weight'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75925f79-15ba-46ce-a3f1-404178485e63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
